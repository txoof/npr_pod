{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright 2016 Aaron ciuffo\n",
    "\n",
    "version = '''NPR Podcast Downloader V5.0\n",
    "\n",
    "by Aaron Ciuffo (txoof.com)\n",
    "released without warranty under GPLV3:\n",
    "http://www.gnu.org/licenses/gpl-3.0.html\n",
    "Please don't sue me.\n",
    "'''\n",
    "\n",
    "programName = 'podcastdownload'\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime # for time stuff\n",
    "import pytz\n",
    "import logging # logging library\n",
    "from urllib2 import urlopen # standard library for interfacing with web resources\n",
    "from urllib2 import URLError\n",
    "import re # regular expressions\n",
    "import json # handle JSON objects\n",
    "import os # Opperating System interface \n",
    "import sys # internal opperations including a list of imported modules\n",
    "import fnmatch # used by cleanup method in Episode\n",
    "import glob # used by m3u method - consider replacing with some other library\n",
    "import shutil # used by cleanup method\n",
    "import argparse # parse command line arguments\n",
    "import ConfigParser # parse config files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    " * Adapt NPREpisode object to use new class attributes for output paths\n",
    " * complete the cleanup method\n",
    " * remove any 'stale' episodes\n",
    " * add a check to see if a program is already downloaded (maybe look for m3u) or at the download log\n",
    " \n",
    " \n",
    "\n",
    "By default teh script should not repeat a download unless asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadModules():\n",
    "    '''load non standard python modules'''\n",
    "    import logging\n",
    "    logging.basicConfig()\n",
    "    logging.debug('loading module: requests')\n",
    "    try:\n",
    "        global requests\n",
    "        import requests\n",
    "    except Exception as e:\n",
    "        logging.critical('Fatal Error\\nFailed to load module: requests\\n%s', e)\n",
    "        logging.critical('Please install requests module: http://docs.python-requests.org/')\n",
    "        exit(2)\n",
    "        return(False)\n",
    "\n",
    "    logging.debug('loading module: mutagen.mp3')\n",
    "    # create a global list of all the taggers available\n",
    "    global taggers\n",
    "    taggers = {}\n",
    "    try:\n",
    "        global MP3\n",
    "        from mutagen.mp3 import EasyMP3 as MP3\n",
    "    except Exception, e:\n",
    "        logging.critical('Failed to load module: mutagen.mp3\\n%s', e)\n",
    "        logging.critical('mp3 tagging may not be available')    \n",
    "    taggers['mp3'] = MP3\n",
    "\n",
    "    \n",
    "    logging.debug('loading module: mutagen.mp4')\n",
    "    try:\n",
    "        global MP4\n",
    "        from mutagen.mp4 import MP4\n",
    "    except Exception, e:\n",
    "        logging.critical('Failed to load module: mutagen.mp4\\n%s', e)\n",
    "        logging.critical('mp4 tagging may not be available')    \n",
    "    taggers['mp4'] = MP4\n",
    "\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Episode():\n",
    "    '''Podcast episode object'''\n",
    "\n",
    "    def __init__(self, name = 'No Name', programURL = 'undef', showDate = None, outputBasePath = './', \n",
    "                 m3u = 'playlist.m3u', downloadLog = 'download.log'):\n",
    "        '''\n",
    "        Args:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "            \n",
    "        Attributes:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            segments (list): Segment() objects to be downloaded\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            outputShowPath (str): path within outputBasePath - slugified version of name\n",
    "            outputPath (str): path within outputShowPath - set to outputShowPath by default\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "        '''\n",
    "        self.name = name # str\n",
    "        self.programURL = programURL # str\n",
    "        self.segments = [] # list\n",
    "        self.showDate = showDate # str\n",
    "        self.outputBasePath = self._slash(outputBasePath) # str\n",
    "        self.outputShowPath = self.outputBasePath + self._slash(self._slugify(self.name))\n",
    "        self.outputPath = self.outputShowPath\n",
    "        self.m3u = m3u\n",
    "        self.downloadLog = downloadLog   \n",
    "    \n",
    "    def attributes(self, display = None):\n",
    "        '''\n",
    "        method to show relevant attributes of\n",
    "        Args:\n",
    "            display (list): list of specific attributes to display\n",
    "        Retruns:\n",
    "            Specific attributes\n",
    "        '''\n",
    "        if isinstance(display, list):\n",
    "            display = display\n",
    "        else:\n",
    "            display = ['name', 'programURL', 'showDate', 'outputBasePath', 'outputShowPath', 'outputPath', \n",
    "                   'm3u', 'downloadLog']\n",
    "        attributes = {}\n",
    "        for key in self.__dict__:\n",
    "            if (key in display) and (key in self.__dict__):\n",
    "                attributes[key] = self.__dict__[key]\n",
    "        \n",
    "        return(attributes)\n",
    "                \n",
    "        \n",
    "    \n",
    "    def _slugify(self, value):\n",
    "        \"\"\"\n",
    "        Normalizes string, converts to lowercase, removes non-alpha characters,\n",
    "        and converts spaces to hyphens.\n",
    "\n",
    "        From Django's \"django/template/defaultfilters.py\".\n",
    "        Args:\n",
    "            value (str): string to be normalized for use with a filename\n",
    "        \n",
    "        Returns:\n",
    "            unicode: sluggified string\n",
    "        \"\"\"\n",
    "        _slugify_strip_re = re.compile(r'[^\\w\\s-]')\n",
    "        _slugify_hyphenate_re = re.compile(r'[-\\s]+')\n",
    "\n",
    "        import unicodedata\n",
    "        if not isinstance(value, unicode):\n",
    "            value = unicode(value)\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore')\n",
    "        value = unicode(_slugify_strip_re.sub('', value).strip())\n",
    "        return _slugify_hyphenate_re.sub('-', value)\n",
    "\n",
    "    def _slash(self, value):\n",
    "        '''\n",
    "        Ensures path has a trailing slash\n",
    "        \n",
    "        Args:\n",
    "            value (str): string to check and modify\n",
    "        \n",
    "        Returns:\n",
    "            value (str): string with trailing slash\n",
    "            \n",
    "        '''\n",
    "        if not re.match('.*\\/$', value):\n",
    "            logging.debug('adding trailing slash to path: %s', value)\n",
    "            return(value + '/')\n",
    "        else:\n",
    "            return(value)\n",
    "    \n",
    "    def setOutputPath(self, outputShowPath = None, outputEpisodePath = None):\n",
    "        '''\n",
    "        Method to update the output paths\n",
    "        Args:\n",
    "            outputShowPath (str): path within the outputBasePath\n",
    "            outputEpisodePath (str): path within outputShowPath\n",
    "        Returns:\n",
    "            outputEpisodePath (str)\n",
    "        '''\n",
    "        if outputShowPath:\n",
    "            self.outputShowPath = self._slash(self.outputBasePath) + self._slash(outputShowPath)\n",
    "        \n",
    "        if outputEpisodePath:\n",
    "            self.outputPath = self._slash(self.outputShowPath) + self._slash(outputEpisodePath)\n",
    "        else:\n",
    "            self.outputPath = self.outputShowPath\n",
    "            \n",
    "        return(self.outputPath)\n",
    "    \n",
    "    def setM3U(self, name = 'playlist'):\n",
    "        '''\n",
    "        Update the m3u file name\n",
    "        Args:\n",
    "            name (str): filename for the m3u\n",
    "        '''\n",
    "        self.m3u = self._slugify(name) + '.m3u'\n",
    "        return(True)\n",
    "    \n",
    "    def writeM3U(self, filename = False):\n",
    "        '''\n",
    "        Write M3U playlist for the episode in the root of the output directory\n",
    "        Args:\n",
    "            filename (str): path to output filename\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        \n",
    "        logging.info('opening m3u playlist: %s', self.m3u)\n",
    "        if filename:\n",
    "            self.setm3u(filename)\n",
    "        \n",
    "        try:\n",
    "            #m3ufile = open(self.outputBasePath + self.m3u, 'w')\n",
    "            m3ufile = open(self._slash(self.outputPath) + self.m3u, 'w')\n",
    "        except Exception as e:\n",
    "            logging.error('could not open m3u file: %s\\n%s', self.m3u, e)\n",
    "            return(False)\n",
    "        logging.debug('writing segments to: %s', self.m3u)\n",
    "        # recurse all the segments \n",
    "        for segment in self.segments:\n",
    "            # if it was successfully downloaded write it to the m3u file\n",
    "            if segment.downloaded:\n",
    "                logging.debug('writing segment to m3u file: %s', segment.filename)\n",
    "                try:\n",
    "                    #m3ufile.write(self.outputPath + segment.filename + '\\n')\n",
    "                    m3ufile.write(segment.filename + '\\n')\n",
    "                except Exception as e:\n",
    "                    logging.error('could not write to: %s\\n%s', self.m3u, e)\n",
    "                    logging.error('halting m3u writing')\n",
    "                    return(False)\n",
    "        # cleanup\n",
    "        try:\n",
    "            m3ufile.close()\n",
    "        except Exception as e:\n",
    "            logging.error('could not close m3u file: %s\\n%s', self.m3u, e)\n",
    "            return(False)\n",
    "        \n",
    "        return(True)\n",
    "    \n",
    "    \n",
    "    def download(self, dryrun = False, timeout = 5):\n",
    "        '''\n",
    "        Download all segments in self.segment into self.outputPath\n",
    "        Args:\n",
    "            dryrun (bool): When true do all other steps, but do not download and return: False\n",
    "            timeout (real): time in seconds to wait for a download to complete before timing out\n",
    "        \n",
    "        Returns: \n",
    "            bool: True for successful download of all segments\n",
    "        '''\n",
    "        \n",
    "        success = True\n",
    "        lockfile = self.outputPath + '.' + programName + '.lock'\n",
    "        logging.info('downloding program: %s', self.name)\n",
    "        \n",
    "        # check for output path\n",
    "        logging.debug('checking for output directory: %s', self.outputPath)\n",
    "        if not os.path.isdir(self.outputPath):\n",
    "            logging.debug('output directory (%s) not found', self.outputPath)\n",
    "            logging.debug('attempiting to create output directory')\n",
    "            try:\n",
    "                os.makedirs(self.outputPath)\n",
    "            except Exception as e:\n",
    "                logging.error('could not create outputpath for this episdoe at: %s\\n%s', self.outputPath, e)\n",
    "                logging.error('download failed')\n",
    "                return(False)\n",
    "            \n",
    "            # make a 'lock file' in the folder to help with cleanup later  \n",
    "            logging.debug('writing lockfile: %s', lockfile)\n",
    "            try:\n",
    "                with open(lockfile, 'a'):\n",
    "                    os.utime(lockfile, None)\n",
    "            except Exception as e:\n",
    "                logging.error('could not create lockfile: %s', lockfile)\n",
    "                logging.error('file error: %s', e)\n",
    "        \n",
    "        # check for existing m3u files; stop execution if it exists\n",
    "        if len(glob.glob(self.outputPath + '/*.m3u')) > 0:\n",
    "            logging.info('episode previously downloaded; skipping')\n",
    "            return(False)\n",
    "        \n",
    "        logging.debug('dryrun = %s', dryrun)\n",
    "        logging.debug(type(dryrun))\n",
    "        if dryrun:\n",
    "            logging.debug('downloads will be simulated')\n",
    "        for segment in self.segments:\n",
    "            # update the path for the current segment\n",
    "            filePath = self.outputPath + segment.filename\n",
    "            logging.debug('downloading %s', segment.audioURL)\n",
    "            if not dryrun:\n",
    "                try:\n",
    "                    audioFile = urlopen(segment.audioURL, timeout = timeout).read()\n",
    "                except URLError as e:\n",
    "                    logging.warning('could not download segment number: %s', segment.number)\n",
    "                    logging.warning('error: %s; timeout: %s', e, timeout)\n",
    "                    success = False\n",
    "                    continue\n",
    "            \n",
    "            logging.info('writing file to %s', filePath)\n",
    "            \n",
    "            if not dryrun:\n",
    "                try:\n",
    "                    with open(filePath, 'wb') as code:\n",
    "                        code.write(audioFile)\n",
    "                        # record if the writing was successful\n",
    "                        segment.downloaded = True\n",
    "                except Exception as e:\n",
    "                    logging.warning('could not write segment number %s to %s\\nerrors follow', segment.number, filePath)\n",
    "                    logging.warning(e)\n",
    "                    success = False\n",
    "                    continue\n",
    "            else:\n",
    "                # record succsessful downloading of all segments when doing a dry run\n",
    "                segment.downloaded = True\n",
    "                # Dry runs return \"false\"\n",
    "                success = False\n",
    "            \n",
    "        \n",
    "        self.logDownload()\n",
    "            \n",
    "        return(success)       \n",
    "            \n",
    "    def logDownload(self):\n",
    "        '''\n",
    "        Log successfully downloaded episodes\n",
    "        Args:\n",
    "        \n",
    "        Returns: \n",
    "            bool: True\n",
    "        '''\n",
    "        logFile = self.outputBasePath + self.downloadLog\n",
    "        \n",
    "        logging.debug('opening log file: %s', logFile)\n",
    "        try:\n",
    "            f = open(logFile, 'a')\n",
    "        except Exception as e:\n",
    "            logging.error('could not open log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        try: \n",
    "            f.write(self.outputPath + '\\n')\n",
    "        except Exception as e:\n",
    "            logging.error('could not write to log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        try:\n",
    "            f.close()\n",
    "        except Exception as e:\n",
    "            logging.error('could not close log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        return(True)\n",
    "            \n",
    "    \n",
    "    def addSegment(self, segment):\n",
    "        '''\n",
    "        Add a downloadable segment to the segment list\n",
    "        Args:\n",
    "            segment (Segment): Segment() object containing information\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        self.segments.append(segment)\n",
    "        return(True)\n",
    "        \n",
    "            \n",
    "    def tagSegments(self):\n",
    "        '''\n",
    "        Tag all downloaded segments\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        logging.info('tagging segments')\n",
    "        for segment in self.segments:\n",
    "            filename = self.outputPath + segment.filename\n",
    "            try:\n",
    "                filetype = re.search('\\.(\\w+$)', filename).group(1)\n",
    "            except:\n",
    "                filetype = None\n",
    "\n",
    "            if filetype.lower() in taggers:\n",
    "                logging.debug('tagging %s', filename)\n",
    "                myTagger = taggers[filetype]\n",
    "                audio = myTagger(filename)\n",
    "                \n",
    "                audio['title'] = segment.title\n",
    "                audio['tracknumber'] = str(segment.number)\n",
    "                audio['album'] = segment.programName\n",
    "                \n",
    "                try:\n",
    "                    audio.save()\n",
    "                except Exception as e:\n",
    "                    logging.error('could not write tags for: %s\\n%s', filename, e)        \n",
    "            else:\n",
    "                logging.info('could not tag, unknown filetype: %s', filename) \n",
    "                \n",
    "    def cleanUp(self, keep = 2, dryrun = False, lockfile = '*.lock'):\n",
    "        '''\n",
    "        Remove stale episodes, keeping at maximum keep episodes\n",
    "\n",
    "        Args:\n",
    "            keep (int): maximum number of episodes to keep\n",
    "            dryrun (bool): when true, do not actually delete anything\n",
    "            lockfile (str): lockfile pattern glob to use when searching for lockfiles; default:*.lock\n",
    "        Returns:\n",
    "            removed (list): removed paths\n",
    "        '''\n",
    "      \n",
    "        logging.info('cleaning up stale shows for %s', self.name)\n",
    "        if not isinstance(keep, int):\n",
    "            logging.error('%s is not an integer: keep')\n",
    "        logging.info('keeping a maximum of %s shows', keep)\n",
    "        # candididate directories that contain lockfiles for deletion\n",
    "        matchdir = {}\n",
    "        logging.debug('searching path: %s', self.outputShowPath)\n",
    "        for root, dirnames, filenames in os.walk(self.outputShowPath):\n",
    "            logging.debug('%s', root)\n",
    "            for filename in fnmatch.filter(filenames, lockfile):\n",
    "                logging.debug('      %s', filename)\n",
    "                matchdir[root] = filename\n",
    "        \n",
    "        logging.debug('previously downloaded episodes found: %s', len(matchdir))\n",
    "        # files to delete\n",
    "        delete = []\n",
    "        \n",
    "        # files successfully deleted:\n",
    "        removed = []\n",
    "        for directory in range(0, len(sorted(matchdir))-keep):\n",
    "            logging.debug('flagged for deletion: %s', sorted(matchdir)[directory])\n",
    "            delete.append(sorted(matchdir)[directory])\n",
    "        \n",
    "        for key, val in enumerate(delete):\n",
    "            lockfile = os.path.join(delete[key], matchdir[delete[key]])\n",
    "            logging.debug('attempting to clean episode files in: %s', delete[key])\n",
    "            # double check that a *.lock file exists before attempting a delete\n",
    "            if os.path.isfile(lockfile):\n",
    "                logging.debug('found lock file in path: %s', delete[key])\n",
    "\n",
    "                if dryrun:\n",
    "                    logging.debug('dryrun: simulating deletion (nothing will be removed)')\n",
    "                else:\n",
    "                    logging.debug('deleting path: %s\\n', delete[key])\n",
    "                    try:\n",
    "                        shutil.rmtree(delete[key])\n",
    "                        # record those paths removed\n",
    "                        removed.append(delete[key])\n",
    "                    except OSError as e:\n",
    "                        logging.error('could not delete path: %s', e)\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                logging.warn('discovered missing lock file when attempting cleanup: %s', lockfile)\n",
    "                logging.warn('manual deletion required: %s', delete[key])\n",
    "                logging.warn('skipping path: %s\\n', delete[key])\n",
    "\n",
    "        return(removed)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  DEBUG 2017-02-11 14:55] adding trailing slash to path: ./output\n",
      "[  DEBUG 2017-02-11 14:55] adding trailing slash to path: Morning-Edition\n",
      "[   INFO 2017-02-11 14:55] fetching episode info via HTML method\n",
      "[  DEBUG 2017-02-11 14:55] source: http://www.npr.org/programs/morning-edition/\n",
      "[  DEBUG 2017-02-11 14:55] HTML retrieved successfully\n",
      "[   INFO 2017-02-11 14:55] show date: 2017-02-10\n",
      "[  DEBUG 2017-02-11 14:55] JSON program information found for MORNING EDITION\n",
      "[  DEBUG 2017-02-11 14:55] setting name to: Morning Edition\n",
      "[  DEBUG 2017-02-11 14:55] segments found: 17\n",
      "[  DEBUG 2017-02-11 14:55] adding trailing slash to path: 2017-02-10_MED\n",
      "[  DEBUG 2017-02-11 14:55] output path set to: ./output/Morning-Edition/2017-02-10_MED/\n",
      "[  DEBUG 2017-02-11 14:55] m3u filename set to: 2017-02-10-MORNING-EDITION.m3u\n",
      "[  DEBUG 2017-02-11 14:55] 1 - Trump Travel Ban Still On Hold After Appeals Court Decision\n",
      "[  DEBUG 2017-02-11 14:55] 2 - The Ethics Of Trump Hosting Japan's Shinzo Abe At Mar-A-Lago\n",
      "[  DEBUG 2017-02-11 14:55] 3 - Opposition Denounces President And Fights Break Out In South African Parliament\n",
      "[  DEBUG 2017-02-11 14:55] 4 - John Oliver On Facts, Donald Trump And The Supreme Court For Dogs \n",
      "[  DEBUG 2017-02-11 14:55] 5 - Hospital Windows Provide A Great View To Soccer Stadium's Action\n",
      "[  DEBUG 2017-02-11 14:55] 6 - Broadcasting Board of Governors' Chief On The Future Of VOA\n",
      "[  DEBUG 2017-02-11 14:55] 7 - U.S. Bases On Japanese Island Of Okinawa Have Long Been Contentious\n",
      "[  DEBUG 2017-02-11 14:55] 8 - Trump's Possible 'Border Adjustment Tax,' Explained\n",
      "[  DEBUG 2017-02-11 14:55] 9 - To Get His First Oscar Nod, Justin Timberlake Had To Act Like A Troll\n",
      "[  DEBUG 2017-02-11 14:55] 10 - The Political Battles Ahead Over Remaining Trump Cabinet Picks\n",
      "[  DEBUG 2017-02-11 14:55] 11 - Self-Driving Cars Could Ease Our Commutes, But That'll Take A While\n",
      "[  DEBUG 2017-02-11 14:55] 12 - Fordham University Report Examines ISIS Prosecutions In The U.S.\n",
      "[  DEBUG 2017-02-11 14:55] 13 - A Romance That Began With A Mistake\n",
      "[  DEBUG 2017-02-11 14:55] 14 - U.S. Army Drone Disappears During A Training Flight Over Arizona\n",
      "[  DEBUG 2017-02-11 14:55] 15 - Japan's Shinzo Abe To Meet With Trump In White House\n",
      "[  DEBUG 2017-02-11 14:55] 16 - Brazilian State Suffers Through Days Of Violence During Police Strike\n",
      "[  DEBUG 2017-02-11 14:55] 17 - TripAdvisor Backs Appeals Court Refusal To Reinstate Travel Ban\n",
      "[   INFO 2017-02-11 14:55] downloding program: MORNING EDITION\n",
      "[  DEBUG 2017-02-11 14:55] checking for output directory: ./output/Morning-Edition/2017-02-10_MED/\n",
      "[   INFO 2017-02-11 14:55] episode previously downloaded; skipping\n",
      "[   INFO 2017-02-11 14:55] cleaning up stale shows for MORNING EDITION\n",
      "[   INFO 2017-02-11 14:55] keeping a maximum of 3 shows\n",
      "[  DEBUG 2017-02-11 14:55] searching path: ./output/Morning-Edition/\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-02-06_MED\n",
      "[  DEBUG 2017-02-11 14:55]       podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-02-09_MED\n",
      "[  DEBUG 2017-02-11 14:55]       podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-02-10_MED\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-26\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-29\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-27\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-11 14:55]       podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-28\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] ./output/Morning-Edition/2017-01-25\n",
      "[  DEBUG 2017-02-11 14:55]       .podcastdownload.lock\n",
      "[  DEBUG 2017-02-11 14:55] previously downloaded episodes found: 12\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-25\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-26\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-27\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-28\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-29\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-11 14:55] flagged for deletion: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-25\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-25\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-26\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-26\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-27\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-27\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-28\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-28\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-29\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-29\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n",
      "[  DEBUG 2017-02-11 14:55] attempting to clean episode files in: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-11 14:55] found lock file in path: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-11 14:55] dryrun: simulating deletion (nothing will be removed)\n"
     ]
    }
   ],
   "source": [
    "#myNPR = NPREpisode(name = 'Weekend Edition Saturday', programURL = 'http://www.npr.org/programs/weekend-edition-saturday/', outputBasePath = './output')\n",
    "myNPR = NPREpisode(name = 'Morning Edition', programURL = 'http://www.npr.org/programs/morning-edition/', outputBasePath = './output')\n",
    "myNPR.getepisode_HTML()\n",
    "myNPR.download(dryrun = True, timeout = .0001)\n",
    "#myNPR.writeM3U()\n",
    "foo = myNPR.cleanUp(3, dryrun = True)\n",
    "#myNPR.attributes("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NPREpisode(Episode, object):\n",
    "    '''NPR program episode object\n",
    "        Args:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "            jsonData \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, name = 'unknown', programURL = None, outputBasePath = './', m3u ='playlist.m3u', downloadLog = 'download.log'):\n",
    "        super(NPREpisode, self).__init__(name = name, programURL = programURL, \n",
    "                                         outputBasePath = outputBasePath, m3u = m3u, downloadLog = downloadLog)\n",
    "        self.jsonData = None\n",
    "\n",
    "    def recentEpisodes(self):\n",
    "        '''Identify the most recent episodes\n",
    "        Not yet implemented\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def getepisode_API():\n",
    "        '''\n",
    "        Use the NPR API to get a list of episodes\n",
    "        Not yet implemented\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def getepisode_HTML(self):\n",
    "        '''\n",
    "        Scrape the HTML for JSON containing the date segment and title information\n",
    "        Attributes set here:\n",
    "            self.jsonData (json obj) - JSON listing of episodes from NPR\n",
    "            self.showDate (str) - YYYY-MM-DD formatted string\n",
    "            self.name (str) - human readable show name \n",
    "            self.segments (:obj: Segment) - episode segments are populated and added\n",
    "\n",
    "        Returns: \n",
    "            bool: True if episode information is scraped from the HTML, False otherwise\n",
    "        '''\n",
    "        \n",
    "        logging.info('fetching episode info via HTML method')\n",
    "        logging.debug('source: %s' % self.programURL)\n",
    "        \n",
    "        # search terms hardcoded here\n",
    "        search_PlayAll = \"<b.*data-play-all='({.*})'><\\/b>\" #re search string for JSON data in program HTML\n",
    "        search_FileName = \"(^[\\s|\\w|\\.|'|-]*)\\[?|$]\" #(anySpaces OR anyWords OR anyPeriod OR any' OR any-)? OR EOL\n",
    "        search_showDate = \"datetime=\\\"(\\d{4}-\\d{2}-\\d{2})\" #re search for show date\n",
    "               \n",
    "        \n",
    "        # variables defined here\n",
    "        filename = '' # extracted filename for each segment\n",
    "        \n",
    "        # add an extension to help differentiate between episodes; set to epoch seconds to prevent clobbering\n",
    "        # if no valid extension is set elsewhere\n",
    "        output_extension = int((datetime.now() - datetime.utcfromtimestamp(0)).total_seconds())\n",
    "        \n",
    "       \n",
    "        try: # fetch the full show HTML\n",
    "            programHTML = urlopen(self.programURL).read()\n",
    "        except Exception as e:\n",
    "            logging.warning('could not fetch episode information from %s' % self.programURL)\n",
    "            logging.error(e)\n",
    "            return(False)\n",
    "        logging.debug('HTML retrieved successfully')\n",
    "        \n",
    "        # find the show date and record it \n",
    "        self.showDate = re.search(search_showDate, programHTML).group(1)\n",
    "        \n",
    "        if len(self.showDate) < 1:\n",
    "            logging.warning('no valid showDate found')\n",
    "        else: logging.info('show date: %s', self.showDate)\n",
    "        \n",
    "        try: # find the JSON program data\n",
    "            self.jsonData = json.loads(re.search(search_PlayAll, programHTML).group(1))\n",
    "        except Exception as e:\n",
    "            logging.error('no valid JSON episode listing found in HTML from %s', self.programURL)\n",
    "            logging.error(e)\n",
    "            return(False)\n",
    "        \n",
    "        # check that some JSON data was found - not terribly robust\n",
    "        if len(self.jsonData['audioData']) > 1:\n",
    "            logging.debug('JSON program information found for %s', self.jsonData['audioData'][0]['program'].upper())\n",
    "            logging.debug('setting name to: %s', self.name)\n",
    "            self.name = self.jsonData['audioData'][0]['program'].upper() # set the episode name\n",
    "            logging.debug('segments found: %s', len(self.jsonData['audioData']))\n",
    "        else:\n",
    "            logging.warn('no valid audioData found in JSON object for this program')\n",
    "            return(False)\n",
    "        \n",
    "        # grab the first character of each word in the program name; grab the last two characters of the last word\n",
    "        if len(self.name) > 0:\n",
    "            short_name = '_'\n",
    "            output_extension = '_'\n",
    "            for each, val in enumerate(self.name.split(' ')):\n",
    "                if each + 1 >= len(self.name.split(' ')):\n",
    "                    char = 2\n",
    "                else: \n",
    "                    char = 1\n",
    "                output_extension = output_extension + val[:char]\n",
    "                short_name = short_name + val[:char]\n",
    "\n",
    "        # create a sub directory within the output path\n",
    "        self.setOutputPath(outputEpisodePath = self.showDate + short_name) \n",
    "        logging.debug('output path set to: %s', self.outputPath)\n",
    "        \n",
    "        #set m3u name\n",
    "        self.setM3U(self.showDate + '-' + self.name)\n",
    "        logging.debug('m3u filename set to: %s', self.m3u)\n",
    "        \n",
    "        # recurse the JSON object and find all the audioData information\n",
    "        for key, val in enumerate(self.jsonData['audioData']):\n",
    "            logging.debug('%s - %s', int(key)+1, val['title'] )\n",
    "            try:\n",
    "                audioURL = val['audioUrl'] \n",
    "                title = val['title']\n",
    "            except Exception as e:\n",
    "                    logging.warning('failed to parse JSON data: %s', e)\n",
    "                    \n",
    "            number = int(key)+1 # set the human readable segment number\n",
    "            filename = re.search(search_FileName, val['audioUrl'].split('/')[-1:][0]).group(1) # set the filename\n",
    "            \n",
    "            # append the segment number\n",
    "            filename = str(number).zfill(3) + '_' + filename\n",
    "            \n",
    "            if filename < 1:\n",
    "                logging.warning('no filename found; dropping segment')\n",
    "                continue\n",
    "\n",
    "            self.addSegment(Segment(audioURL = audioURL, filename = filename, \n",
    "                                    number = number, programName = self.name,\n",
    "                                    title = title))\n",
    "            \n",
    "        return(True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Segment():\n",
    "    '''One segment of a podcast'''\n",
    "    \n",
    "    def __init__(self, audioURL, filename, number, programName, title = None):\n",
    "        '''\n",
    "        Args:\n",
    "            audioURL (str): URL to specific downloadable content\n",
    "            filename (str): output filename\n",
    "            title (str): human readable segment title\n",
    "            programName (str): program Name\n",
    "            number (int): ordinal number of segment\n",
    "            downloaded (boo): true if segment was successfully downloaded\n",
    "            \n",
    "        '''\n",
    "        self.audioURL = audioURL\n",
    "        self.number = number\n",
    "        self.filename = filename\n",
    "        self.title = title\n",
    "        self.programName = programName\n",
    "        self.downloaded = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class showConfig():\n",
    "    '''Configuration object for a downloadable show'''\n",
    "   \n",
    "    def __init__(self, optionsDict = {}):\n",
    "        '''\n",
    "        Args:\n",
    "            optionsDict (dict): dictionary of options to be used in configuration\n",
    "                showname (str): human readable string\n",
    "                fetchmethod (str): method for downloading show (NPR_HTML or NRP_API)\n",
    "                programs (int): number of programs to keep\n",
    "                updatedays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "                updatetime (str): time in 24H HH:MM format after which an update should be attempted\n",
    "                timezone (str): timezone in which to preform time calculatinos\n",
    "                url (str): url to NPR program page\n",
    "        Attributes:\n",
    "            options (dict): dictionary of options\n",
    "            showName (str): human readable name of show\n",
    "            fetchMethod (str): method for downloading show (NPR_HTML or NPR_API)\n",
    "            programs (int): number of programs to keep\n",
    "            updateDays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "            updateTime (str): time in HH:MM after which an update should be attempted\n",
    "            timezone (str): timezone in which to preform time calculations\n",
    "            url (str): url to NPR program page\n",
    "    \n",
    "        '''\n",
    "        \n",
    "        self.options = optionsDict\n",
    "        self.showName = 'No Name'\n",
    "        self.fetchMethod = 'NPR_HTML'\n",
    "        self.programs = 10\n",
    "        self.updateDays = []\n",
    "        self.updateTime = ''\n",
    "        self.timezone = 'EST'\n",
    "        self.url = None\n",
    "        \n",
    "    def verifyConfig(self):\n",
    "        '''\n",
    "        \n",
    "        Validates and sets configuration paramaters for a downloadable show:\n",
    "        \n",
    "        Attributes:\n",
    "            showName (str): human readable name of show\n",
    "            fetchMethod (str): method for downloading show (NPR_HTML or NPR_API)\n",
    "            programs (int): number of programs to keep\n",
    "            updateDays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "            updateTime (str): time in HH:MM after which an update should be attempted\n",
    "            timezone (str): timezone in which to preform time calculations\n",
    "            \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns: \n",
    "            bool: True - configuration is OK or has been made OK\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        logging.debug('verifying configuration')\n",
    "        \n",
    "        if 'showname' in self.options:\n",
    "            self.showName = self.options['showname']\n",
    "            logging.debug('show name set to: %s', self.showName)\n",
    "        else: \n",
    "            self.showName = 'Unknown Show'\n",
    "            logging.debug('no show name found; set to: %s', self.showName)\n",
    "            \n",
    "        if 'fetchmethod' in self.options:\n",
    "            self.fetchMethod = self.options['fetchmethod']\n",
    "            logging.debug('fetchmethod set to: %s', self.fetchMethod)\n",
    "        else:\n",
    "            logging.error('no fetchmethod set; setting to: %s', self.fetchMethod)\n",
    "        \n",
    "        if 'programs' in self.options:\n",
    "            try:\n",
    "                self.programs = int(self.options['programs'])\n",
    "            except ValueError as e:\n",
    "                logging.error('programs option not an integer: %s', e)\n",
    "                logging.error('programs set to: %s', self.programs)\n",
    "        else:\n",
    "            logging.error('no programs setting found in configuration file; set to: %s', self.programs)\n",
    "            \n",
    "        defaultUpdateDays = [1, 2, 3, 4, 5, 6, 7]\n",
    "        if 'updatedays' in self.options:\n",
    "            # remove any non-numerals, -, or commas\n",
    "            self.options['updatedays'] = re.sub('[^\\,0-9]+', '', self.options['updatedays'])\n",
    "            # clear out any superflous commas\n",
    "            self.options['updatedays'] = re.sub('\\,\\,', ',', self.options['updatedays'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                self.updateDays = map(int, self.options['updatedays'].split(','))\n",
    "            except ValueError as e:\n",
    "                logging.warn('bad or missing update date format: %s',e )\n",
    "                logging.warn('using sun through sat')\n",
    "                self.updateDays = defaultUpdateDays\n",
    " \n",
    "            badValues = []\n",
    "            for index in self.updateDays:\n",
    "                # check for bad values that are less than 1 or greater than 7\n",
    "                if index > 7 or index < 1:\n",
    "                    logging.warn('found invalid day in configuration file: %s',index)\n",
    "                    badValues.append(index)   \n",
    "                    \n",
    "            # get rid of bad values\n",
    "            for index in badValues:\n",
    "                logging.warn('removing invalid day: %s', index)\n",
    "                self.updateDays.remove(index)\n",
    "            # sort the list \n",
    "            self.updateDays.sort()\n",
    "        else:\n",
    "            # supply a list if none is supplied\n",
    "            logging.warn('no update days were supplied using sun through sat')\n",
    "            self.updateDays = defaultUpdateDays\n",
    "        \n",
    "        \n",
    "        # do some validation of valid timezones\n",
    "        if 'timezone' in self.options:\n",
    "            if self.options['timezone'].upper() in pytz.all_timezones:\n",
    "                self.timezone = self.options['timezone'].upper()\n",
    "            else: \n",
    "                logging.error('specified timezone not found in database: %s', self.options['timezone'])\n",
    "                logging.error('setting timezone to: UTC')\n",
    "                self.timezone = 'UTC'\n",
    "                \n",
    "        else:\n",
    "            logging.error('no timezone found; setting timezone to: UTC')\n",
    "        \n",
    "        # do some validation of valid times\n",
    "        # time format\n",
    "        timeFMT = '%H:%M'\n",
    "        defaultTime = '23:59'\n",
    "        if 'updatetime' in self.options:\n",
    "            # sanitize the time string datetime.time(datetime.strptime('13:55', timeFMT))\n",
    "            try:\n",
    "                self.updateTime = datetime.time(datetime.strptime(re.sub('[^0-9\\:]+', '', self.options['updatetime']), timeFMT))\n",
    "            except ValueError as e:\n",
    "                logging.error('bad updatetime time format: %s', self.options['updatetime'])\n",
    "                logging.error('setting updatetime to: %s', defaultTime)\n",
    "                self.updateTime = datetime.time(datetime.strptime(defaultTime, timeFMT))    \n",
    "        else:\n",
    "            self.updateTime = datetime.time(datetime.strptime(defaultTime, timeFMT))\n",
    "            \n",
    "        if 'url' in self.options:\n",
    "            if re.match('^http:\\/\\/.*', self.options['url'].lower()):\n",
    "                self.url = self.options['url']\n",
    "            else:\n",
    "                logging.error('no vlaid URL found for %s: %s', self.showName, self.options['url'])\n",
    "                return(False)\n",
    "        else:\n",
    "            logging.error('no valid URL found for %s', self.showName)\n",
    "            return(False)\n",
    "        return(True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "foo = 'http://npr.org/'\n",
    "if re.match('^http:\\/\\/.*', foo):\n",
    "    print 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = '5.5       '\n",
    "try:\n",
    "    print int(foo)\n",
    "except ValueError as e:\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# for testing only\n",
    "log = logging.getLogger()\n",
    "# remove any extra loggers that were added throught the handler calls in the main segment\n",
    "for each in range(0, len(log.handlers)):\n",
    "    log.removeHandler(log.handlers[0])\n",
    "##### REMOVE THIS #####\n",
    "\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    logFormatter = logging.Formatter('[%(levelname)7s %(asctime)s] %(message)s', '%Y-%m-%d %H:%M')\n",
    "    rootLogger = logging.getLogger()\n",
    "    rootLogger.setLevel(logging.DEBUG)\n",
    "\n",
    "    fileHandler = logging.FileHandler(programName+'.log')\n",
    "    fileHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(fileHandler)\n",
    "\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler)\n",
    "    \n",
    "    divider = '*'*10\n",
    "    \n",
    "    logging.info('%s%s started log %s%s', divider, divider, divider, divider)\n",
    "    \n",
    "    # default configuration file\n",
    "    cfgFile = 'settings.ini'\n",
    "    \n",
    "    # list of show configurations found in configuration file\n",
    "    showsConfig = []\n",
    "    \n",
    "    # list of program episodes to download\n",
    "    episodes = []\n",
    "    \n",
    "    \n",
    "    # load non-standard python libraries\n",
    "    loadModules()\n",
    "    \n",
    "    #if argv is None:\n",
    "    #    arv = sys.argv\n",
    "    \n",
    "        # set up a command line parser to deal with everything on the command line\n",
    "\n",
    "    # disable -h for help so the second parser can deal with this\n",
    "    # http://stackoverflow.com/questions/3609852/which-is-the-best-way-to-allow-configuration-options-be-overridden-at-the-comman\n",
    "    cmdlineParser = argparse.ArgumentParser(description = __doc__, \n",
    "                                           formatter_class = argparse.RawDescriptionHelpFormatter,\n",
    "                                          add_help = False)\n",
    "    # handle the jupyter -f option while developing in jupyter ipython notebook\n",
    "    cmdlineParser.add_argument('-f', '--fconfig', help='fake config file', action='store')\n",
    "    # set the configuration file\n",
    "    cmdlineParser.add_argument('-c', '--configfile', help='configuration file', metavar='FILE',\n",
    "                              action='store', default=cfgFile)\n",
    "    # determine if this is a dry run or not\n",
    "    cmdlineParser.add_argument('-d', '--dryrun', help='preform a dry-run with no downloads',\n",
    "                              action='store_true', default=False)\n",
    "    \n",
    "    # reamining arguments stored in unknownArgs\n",
    "    args, unknownArgs = cmdlineParser.parse_known_args()\n",
    "    \n",
    "    # parse the configuration file\n",
    "    defaults = {}\n",
    "    # create a configuration file parser\n",
    "    configParser = ConfigParser.SafeConfigParser()\n",
    "    # read the config file for the \"defaults\" section\n",
    "    logging.debug('%s parsing config file %s', divider, divider)\n",
    "    logging.debug('reading configuraiton file: %s', args.configfile)\n",
    "    configParser.read(args.configfile)\n",
    "    # pull the Defaults section from the ini\n",
    "    defaults.update(dict(configParser.items('Defaults')))\n",
    "    \n",
    "    # merge the command line with the config file options\n",
    "    parser = argparse.ArgumentParser(parents=[cmdlineParser])\n",
    "    \n",
    "    parser.set_defaults(**defaults)\n",
    "    parserArgs = parser.parse_args()\n",
    "    \n",
    "    # verify parserArgs below:\n",
    "    \n",
    "    # Sanitize parserArgs.dryryn; convert strings into boolean as appropriate\n",
    "    falseList = ['false', 'no', 'n']\n",
    "    trueList = ['true', 'y', 'yes']\n",
    "    \n",
    "    if not isinstance(parserArgs.dryrun, bool):\n",
    "        if str(parserArgs.dryrun).lower() in trueList:\n",
    "            parserArgs.dryrun = True\n",
    "\n",
    "        if str(parserArgs.dryrun).lower() in falseList:\n",
    "            logging.debug('converting string to boolean: False')\n",
    "            parserArgs.dryrun = False\n",
    "\n",
    "        # if it is unknown, set to False\n",
    "        if not (str(parserArgs.dryrun).lower() in trueList) and not (str(parserArgs.dryrun).lower() in falseList):\n",
    "            logging.debug('bad dryrun value - check configuration file: %s', parserArgs.dryrun)\n",
    "            logging.debug('setting to: False')\n",
    "            parserArgs.dryrun = False\n",
    "            \n",
    "    print type(parserArgs.dryrun)\n",
    "    \n",
    "    # add a trailing '/' to the output path\n",
    "    if not re.match('.*\\/$', parserArgs.outputpath):\n",
    "        parserArgs.outputpath = str(parserArgs.outputpath) + str('/')\n",
    "\n",
    "    \n",
    "    # search for all the show sections in the configuration file \n",
    "    \n",
    "    # this for loop is a mess; I need to deal with this in a sane way without the continue\n",
    "    sectionIndex = 0\n",
    "    logging.debug('%s searching for shows %s', divider, divider)\n",
    "    for section in configParser.sections():\n",
    "        # find all show descriptiors\n",
    "        if '%' in section and '#' not in section:\n",
    "            logging.debug('%s found show: %s', divider, section)\n",
    "            showsConfig.append(showConfig((dict(configParser.items(section)))))\n",
    "            if showsConfig[sectionIndex].verifyConfig():\n",
    "                # if no name is set, use the show descriptor \n",
    "                if not 'showname' in showsConfig[sectionIndex].options:\n",
    "                    showsConfig[sectionIndex].showName = str(section).replace('%', '')\n",
    "                    logging.warning('No show name found in configuration file\\nusing section name: %s', showsConfig[sectionIndex].showName)\n",
    "            else:\n",
    "                logging.error('unable to verify configuration for %s; discarding', showsConfig[sectionIndex].showName)\n",
    "                # remove the most last list item\n",
    "                showsConfig.pop()\n",
    "                # move on to the next element\n",
    "                continue\n",
    "            sectionIndex += 1\n",
    "\n",
    "    # exit if no shows were found        \n",
    "    if len(showsConfig) == 0:\n",
    "        logging.fatal('no shows found in configuration file: %s', args.configfile)\n",
    "        exit(1)\n",
    "    \n",
    "    # parse each show section in the configuration file, validate and add it to the list for downloading\n",
    "    logging.debug('%s checking for shows to download %s', divider, divider)\n",
    "    for each in showsConfig:\n",
    "        # create a time object (H:M:S)\n",
    "        nowTime = datetime.time(datetime.now(pytz.timezone(each.timezone)))\n",
    "        # create a date object\n",
    "        nowDate = datetime.date(datetime.now(pytz.timezone(each.timezone)))\n",
    "        \n",
    "        # create an NPREpisode object and populate\n",
    "        logging.debug('%s parsing configuration for [%s]', divider, each.showName)\n",
    "        myEpisode = NPREpisode(name = each.showName, outputBasePath = parserArgs.outputpath)\n",
    "        #myEpisode.outputBasePath = parserArgs.outputpath\n",
    "        myEpisode.programURL = each.url\n",
    "                \n",
    "        # check the day of the week; if it's not in range, skip this show\n",
    "        if nowDate.isoweekday() not in each.updateDays:\n",
    "            logging.debug('update days in set timezone for this show (%s) does not include today: %s', each.updateDays, nowDate.isoweekday())\n",
    "            logging.info('skipping episode for show: %s (wrong day)', each.showName)\n",
    "            continue\n",
    "        \n",
    "        # check the time; if it's too early, skip the show\n",
    "        if (nowTime > each.updateTime):\n",
    "            logging.debug('the current time in set timezone for this show (%s) is currently later than set update time: %s', each.timezone, each.updateTime)\n",
    "            logging.info('fetching episode information for show: %s', each.showName)\n",
    "            # add the episode to the download list if the html fetch was successful\n",
    "            if myEpisode.getepisode_HTML():\n",
    "                episodes.append(myEpisode)\n",
    "        else: \n",
    "            logging.debug('the current time in set timezone for this show (%s) is earlier than set update time: %s', each.timezone, each.updateTime)\n",
    "            logging.info('skipping episode for show: %s (too early)', each.showName)\n",
    "            \n",
    "    logging.debug('%s downloading episodes %s', divider, divider)\n",
    "    logging.debug('found %s episodes', len(episodes))\n",
    "    for index, eachEp in enumerate(episodes):\n",
    "        if eachEp.download(parserArgs.dryrun):\n",
    "            # write m3u if there was a successful download\n",
    "            eachEp.writeM3U()\n",
    "            # tag segments if there was a successful download \n",
    "            #if not parserArgs.dryrun:\n",
    "            eachEp.tagSegments()\n",
    "        # this is a bit of a mess: this needs to be added to the episode at some point if it's going to used\n",
    "        logging.debug('%s cleaning show: %s', divider, showsConfig[index].showName)\n",
    "        logging.debug('keeping a maximum of %s episodes', showsConfig[index].programs)\n",
    "        eachEp.cleanUp(keep = showsConfig[index].programs, dryrun = parserArgs.dryrun)\n",
    "    \n",
    "    return(showsConfig)\n",
    "        \n",
    "    \n",
    "        \n",
    "#if __name__ == '__main__':\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO 2017-02-10 19:23] ******************** started log ********************\n",
      "[  DEBUG 2017-02-10 19:23] loading module: requests\n",
      "[  DEBUG 2017-02-10 19:23] loading module: mutagen.mp3\n",
      "[  DEBUG 2017-02-10 19:23] loading module: mutagen.mp4\n",
      "[  DEBUG 2017-02-10 19:23] ********** parsing config file **********\n",
      "[  DEBUG 2017-02-10 19:23] reading configuraiton file: settings.ini\n",
      "[  DEBUG 2017-02-10 19:23] converting string to boolean: False\n",
      "<type 'bool'>\n",
      "[  DEBUG 2017-02-10 19:23] ********** searching for shows **********\n",
      "[  DEBUG 2017-02-10 19:23] ********** found show: %All Things Considered\n",
      "[  DEBUG 2017-02-10 19:23] verifying configuration\n",
      "[  DEBUG 2017-02-10 19:23] show name set to: All Things Considered\n",
      "[  DEBUG 2017-02-10 19:23] fetchmethod set to: NPR_HTML\n",
      "[  DEBUG 2017-02-10 19:23] ********** found show: %Morning Edition\n",
      "[  DEBUG 2017-02-10 19:23] verifying configuration\n",
      "[  DEBUG 2017-02-10 19:23] show name set to: Morning Edition\n",
      "[  DEBUG 2017-02-10 19:23] fetchmethod set to: NPR_HTML\n",
      "[  DEBUG 2017-02-10 19:23] ********** found show: %Wait Wait Don't Tell Me\n",
      "[  DEBUG 2017-02-10 19:23] verifying configuration\n",
      "[  DEBUG 2017-02-10 19:23] show name set to: Wait Wait Don't Tell Me\n",
      "[  DEBUG 2017-02-10 19:23] fetchmethod set to: NPR_HTML\n",
      "[  DEBUG 2017-02-10 19:23] ********** checking for shows to download **********\n",
      "[  DEBUG 2017-02-10 19:23] ********** parsing configuration for [All Things Considered]\n",
      "[  DEBUG 2017-02-10 19:23] adding trailing slash to path: All-Things-Considered\n",
      "[  DEBUG 2017-02-10 19:23] the current time in set timezone for this show (EST) is currently later than set update time: 01:00:00\n",
      "[   INFO 2017-02-10 19:23] fetching episode information for show: All Things Considered\n",
      "[   INFO 2017-02-10 19:23] fetching episode info via HTML method\n",
      "[  DEBUG 2017-02-10 19:23] source: http://www.npr.org/programs/all-things-considered/\n",
      "[  DEBUG 2017-02-10 19:23] HTML retrieved successfully\n",
      "[   INFO 2017-02-10 19:23] show date: 2017-02-09\n",
      "[  DEBUG 2017-02-10 19:23] JSON program information found for ALL THINGS CONSIDERED\n",
      "[  DEBUG 2017-02-10 19:23] setting name to: All Things Considered\n",
      "[  DEBUG 2017-02-10 19:23] segments found: 21\n",
      "[  DEBUG 2017-02-10 19:23] adding trailing slash to path: 2017-02-09_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] output path set to: ./output/All-Things-Considered/2017-02-09_ATCO/\n",
      "[  DEBUG 2017-02-10 19:23] m3u filename set to: 2017-02-09-ALL-THINGS-CONSIDERED.m3u\n",
      "[  DEBUG 2017-02-10 19:23] 1 - General Requests Thousands More Troops To Break Afghanistan 'Stalemate'\n",
      "[  DEBUG 2017-02-10 19:23] 2 - Yemen Requests Review Of Deadly U.S. Military Raid\n",
      "[  DEBUG 2017-02-10 19:23] 3 - Alabama Attorney General Luther Strange Chosen To Replace Jeff Sessions\n",
      "[  DEBUG 2017-02-10 19:23] 4 - Jewish Settlement In The West Bank Tied To Trump Administration\n",
      "[  DEBUG 2017-02-10 19:23] 5 - In Talks With Trump, Japan's Shinzo Abe Will Seek To Smooth Economic Tensions\n",
      "[  DEBUG 2017-02-10 19:23] 6 - Kenyan Court Rules Government Must Not Close Refugee Camp\n",
      "[  DEBUG 2017-02-10 19:23] 7 - Veteran Teaches Therapists How To Talk About Gun Safety When Suicide's A Risk\n",
      "[  DEBUG 2017-02-10 19:23] 8 - Soapmaker Dr. Bronner Releases Posthumous Album Of His Own Words\n",
      "[  DEBUG 2017-02-10 19:23] 9 - In Austin, A Boom In Short-Term Rentals Brings A Backlash\n",
      "[  DEBUG 2017-02-10 19:23] 10 - Students Seek To Re-Create Ancient Beer Recipe Discovered In Pottery Vessels\n",
      "[  DEBUG 2017-02-10 19:23] 11 - Kellyanne Conway Tells Americans To Buy Ivanka Trump's Products\n",
      "[  DEBUG 2017-02-10 19:23] 12 - Former Detainee Describes Atrocities Inside Syrian Prison \n",
      "[  DEBUG 2017-02-10 19:23] 13 - Jeff Sessions Takes Strong Anti-Immigration Views To Justice Department\n",
      "[  DEBUG 2017-02-10 19:23] 14 - West Virginia Families Worry About Access To Addiction Treatment Under Trump\n",
      "[  DEBUG 2017-02-10 19:23] 15 - White House Courts Red State Democrats In Upcoming Legislative Battles\n",
      "[  DEBUG 2017-02-10 19:23] 16 - In Divided Senate, Maine's Susan Collins Emerges As Critical Voice\n",
      "[  DEBUG 2017-02-10 19:23] 17 - As Trump Threatens To Ditch NAFTA, Tijuana Residents Face Uncertainty\n",
      "[  DEBUG 2017-02-10 19:23] 18 - While Others Saw Refugees, This German Professor Saw Human Potential\n",
      "[  DEBUG 2017-02-10 19:23] 19 - Federal Appeals Court Upholds Stay On Trump's Immigration Order\n",
      "[  DEBUG 2017-02-10 19:23] 20 - Federal Appeals Court Refuses To Reinstate Trump's Travel Ban \n",
      "[  DEBUG 2017-02-10 19:23] 21 - Washington AG: 'We Could Not Have Written The Opinion Any Better Ourselves'\n",
      "[  DEBUG 2017-02-10 19:23] ********** parsing configuration for [Morning Edition]\n",
      "[  DEBUG 2017-02-10 19:23] adding trailing slash to path: Morning-Edition\n",
      "[  DEBUG 2017-02-10 19:23] the current time in set timezone for this show (EST) is currently later than set update time: 04:00:00\n",
      "[   INFO 2017-02-10 19:23] fetching episode information for show: Morning Edition\n",
      "[   INFO 2017-02-10 19:23] fetching episode info via HTML method\n",
      "[  DEBUG 2017-02-10 19:23] source: http://www.npr.org/programs/morning-edition/\n",
      "[  DEBUG 2017-02-10 19:23] HTML retrieved successfully\n",
      "[   INFO 2017-02-10 19:23] show date: 2017-02-10\n",
      "[  DEBUG 2017-02-10 19:23] JSON program information found for MORNING EDITION\n",
      "[  DEBUG 2017-02-10 19:23] setting name to: Morning Edition\n",
      "[  DEBUG 2017-02-10 19:23] segments found: 17\n",
      "[  DEBUG 2017-02-10 19:23] adding trailing slash to path: 2017-02-10_MED\n",
      "[  DEBUG 2017-02-10 19:23] output path set to: ./output/Morning-Edition/2017-02-10_MED/\n",
      "[  DEBUG 2017-02-10 19:23] m3u filename set to: 2017-02-10-MORNING-EDITION.m3u\n",
      "[  DEBUG 2017-02-10 19:23] 1 - Trump Travel Ban Still On Hold After Appeals Court Decision\n",
      "[  DEBUG 2017-02-10 19:23] 2 - The Ethics Of Trump Hosting Japan's Shinzo Abe At Mar-A-Lago\n",
      "[  DEBUG 2017-02-10 19:23] 3 - Opposition Denounces President And Fights Break Out In South African Parliament\n",
      "[  DEBUG 2017-02-10 19:23] 4 - John Oliver On Facts, Donald Trump And The Supreme Court For Dogs \n",
      "[  DEBUG 2017-02-10 19:23] 5 - Hospital Windows Provide A Great View To Soccer Stadium's Action\n",
      "[  DEBUG 2017-02-10 19:23] 6 - VOA Chief On The Future Of The News Service\n",
      "[  DEBUG 2017-02-10 19:23] 7 - U.S. Bases On Japanese Island Of Okinawa Have Long Been Contentious\n",
      "[  DEBUG 2017-02-10 19:23] 8 - Trump's Possible 'Border Adjustment Tax,' Explained\n",
      "[  DEBUG 2017-02-10 19:23] 9 - To Get His First Oscar Nod, Justin Timberlake Had To Act Like A Troll\n",
      "[  DEBUG 2017-02-10 19:23] 10 - The Political Battles Ahead Over Remaining Trump Cabinet Picks\n",
      "[  DEBUG 2017-02-10 19:23] 11 - Self-Driving Cars Could Ease Our Commutes, But That'll Take A While\n",
      "[  DEBUG 2017-02-10 19:23] 12 - Fordham University Report Examines ISIS Prosecutions In The U.S.\n",
      "[  DEBUG 2017-02-10 19:23] 13 - A Romance That Began With A Mistake\n",
      "[  DEBUG 2017-02-10 19:23] 14 - U.S. Army Drone Disappears During A Training Flight Over Arizona\n",
      "[  DEBUG 2017-02-10 19:23] 15 - Japan's Shinzo Abe To Meet With Trump In White House\n",
      "[  DEBUG 2017-02-10 19:23] 16 - Brazilian State Suffers Through Days Of Violence During Police Strike\n",
      "[  DEBUG 2017-02-10 19:23] 17 - TripAdvisor Backs Appeals Court Refusal To Reinstate Travel Ban\n",
      "[  DEBUG 2017-02-10 19:23] ********** parsing configuration for [Wait Wait Don't Tell Me]\n",
      "[  DEBUG 2017-02-10 19:23] adding trailing slash to path: Wait-Wait-Dont-Tell-Me\n",
      "[  DEBUG 2017-02-10 19:23] update days in set timezone for this show ([6]) does not include today: 5\n",
      "[   INFO 2017-02-10 19:23] skipping episode for show: Wait Wait Don't Tell Me (wrong day)\n",
      "[  DEBUG 2017-02-10 19:23] ********** downloading episodes **********\n",
      "[  DEBUG 2017-02-10 19:23] found 2 episodes\n",
      "[   INFO 2017-02-10 19:23] downloding program: ALL THINGS CONSIDERED\n",
      "[  DEBUG 2017-02-10 19:23] checking for output directory: ./output/All-Things-Considered/2017-02-09_ATCO/\n",
      "[  DEBUG 2017-02-10 19:23] output directory (./output/All-Things-Considered/2017-02-09_ATCO/) not found\n",
      "[  DEBUG 2017-02-10 19:23] attempiting to create output directory\n",
      "[  DEBUG 2017-02-10 19:23] writing lockfile: ./output/All-Things-Considered/2017-02-09_ATCO/.podcastdownload.lock\n",
      "[  DEBUG 2017-02-10 19:23] dryrun = False\n",
      "[  DEBUG 2017-02-10 19:23] <type 'bool'>\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_general_requests_thousands_more_troops_to_break_afghanistan_stalemate.mp3?orgId=1&topicId=1149&d=155&p=2&story=514365513&t=progseg&e=514263752&seg=1&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/001_20170209_atc_general_requests_thousands_more_troops_to_break_afghanistan_stalemate.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_yemen_requests_review_of_deadly_us_military_raid.mp3?orgId=1&topicId=1122&d=291&p=2&story=514365520&t=progseg&e=514263752&seg=2&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/002_20170209_atc_yemen_requests_review_of_deadly_us_military_raid.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_alabama_attorney_general_luther_strange_chosen_to_replace_jeff_sessions.mp3?orgId=1&topicId=1014&d=231&p=2&story=514365527&t=progseg&e=514263752&seg=3&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/003_20170209_atc_alabama_attorney_general_luther_strange_chosen_to_replace_jeff_sessions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_west_bank_beit_el.mp3?orgId=1&topicId=1009&d=227&p=2&story=514399080&t=progseg&e=514263752&seg=4&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/004_20170209_atc_west_bank_beit_el.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_in_talks_with_trump_japans_shinzo_abe_will_seek_to_smooth_economic_tensions.mp3?orgId=1&topicId=1125&d=221&p=2&story=514259005&t=progseg&e=514263752&seg=5&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/005_20170209_atc_in_talks_with_trump_japans_shinzo_abe_will_seek_to_smooth_economic_tensions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_kenyan_court_rules_government_must_not_close_refugee_camp.mp3?orgId=1&topicId=1126&d=245&p=2&story=514365556&t=progseg&e=514263752&seg=6&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/006_20170209_atc_kenyan_court_rules_government_must_not_close_refugee_camp.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_veteran_teaches_therapists_how_to_talk_about_gun_safety_when_suicides_a_risk.mp3?orgId=150&topicId=1128&d=251&p=2&story=514096861&t=progseg&e=514263752&seg=7&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/007_20170209_atc_veteran_teaches_therapists_how_to_talk_about_gun_safety_when_suicides_a_risk.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_soapmaker_dr_bronner_releases_posthumous_album_of_his_own_words.mp3?orgId=1&topicId=1008&d=227&p=2&story=514365563&t=progseg&e=514263752&seg=8&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/008_20170209_atc_soapmaker_dr_bronner_releases_posthumous_album_of_his_own_words.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_short_term_rental_texas.mp3?orgId=1&topicId=1091&d=368&p=2&story=514309905&t=progseg&e=514263752&seg=9&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/009_20170209_atc_short_term_rental_texas.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_students_seek_to_recreate_ancient_beer_recipe_discovered_in_pottery_vessels.mp3?orgId=1&topicId=1008&d=109&p=2&story=514365570&t=progseg&e=514263752&seg=10&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/010_20170209_atc_students_seek_to_recreate_ancient_beer_recipe_discovered_in_pottery_vessels.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_kellyanne_conway_tells_americans_to_buy_ivanka_trumps_products.mp3?orgId=1&topicId=1014&d=222&p=2&story=514317345&t=progseg&e=514263752&seg=11&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/011_20170209_atc_kellyanne_conway_tells_americans_to_buy_ivanka_trumps_products.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_syrian_torture_victim_speaks.mp3?orgId=1&topicId=1022&d=495&p=2&story=514326212&t=progseg&e=514263752&seg=12&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/012_20170209_atc_syrian_torture_victim_speaks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_jeff_sessions_takes_strong_anti-immigration_views_to_justice_department.mp3?orgId=1&topicId=1014&d=254&p=2&story=514365597&t=progseg&e=514263752&seg=13&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/013_20170209_atc_jeff_sessions_takes_strong_anti-immigration_views_to_justice_department.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_w_va_families_worry_about_access_to_addiction_treatment_under_trump.mp3?orgId=1&topicId=1014&aggIds=509568943&d=230&p=2&story=513963649&t=progseg&e=514263752&seg=14&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/014_20170209_atc_w_va_families_worry_about_access_to_addiction_treatment_under_trump.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_white_house_courts_red_state_democrats_in_upcoming_legislative_battles.mp3?orgId=1&topicId=1014&d=212&p=2&story=514365604&t=progseg&e=514263752&seg=15&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/015_20170209_atc_white_house_courts_red_state_democrats_in_upcoming_legislative_battles.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_in_divided_senate_maines_susan_collins_emerges_as_critical_voice.mp3?orgId=1&topicId=1014&d=278&p=2&story=514365614&t=progseg&e=514263752&seg=16&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/016_20170209_atc_in_divided_senate_maines_susan_collins_emerges_as_critical_voice.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_as_trump_threatens_to_ditch_nafta_tijuana_residents_face_uncertainty.mp3?orgId=1&topicId=1127&d=234&p=2&story=514365621&t=progseg&e=514263752&seg=17&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/017_20170209_atc_as_trump_threatens_to_ditch_nafta_tijuana_residents_face_uncertainty.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_while_others_saw_refugees_this_german_professor_saw_human_potential.mp3?orgId=1&topicId=1007&aggIds=156490415&d=474&p=2&story=513700808&t=progseg&e=514263752&seg=18&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/018_20170209_atc_while_others_saw_refugees_this_german_professor_saw_human_potential.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_travel_ban_ruling_-_7pm.mp3?orgId=1&topicId=1070&d=441&p=2&story=514399835&t=progseg&e=514263752&seg=19&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/019_20170209_atc_travel_ban_ruling_-_7pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_travel_ban_ruling_-_8pm.mp3?orgId=1&topicId=1070&d=297&p=2&story=514405482&t=progseg&e=514263752&seg=20&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/020_20170209_atc_travel_ban_ruling_-_8pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/atc/2017/02/20170209_atc_ferguson_ag.mp3?orgId=1&topicId=1070&d=377&p=2&story=514418684&t=progseg&e=514263752&seg=21&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/All-Things-Considered/2017-02-09_ATCO/021_20170209_atc_ferguson_ag.mp3\n",
      "[  DEBUG 2017-02-10 19:23] opening log file: ./output/download.log\n",
      "[   INFO 2017-02-10 19:23] opening m3u playlist: 2017-02-09-ALL-THINGS-CONSIDERED.m3u\n",
      "[  DEBUG 2017-02-10 19:23] writing segments to: 2017-02-09-ALL-THINGS-CONSIDERED.m3u\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 001_20170209_atc_general_requests_thousands_more_troops_to_break_afghanistan_stalemate.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 002_20170209_atc_yemen_requests_review_of_deadly_us_military_raid.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 003_20170209_atc_alabama_attorney_general_luther_strange_chosen_to_replace_jeff_sessions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 004_20170209_atc_west_bank_beit_el.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 005_20170209_atc_in_talks_with_trump_japans_shinzo_abe_will_seek_to_smooth_economic_tensions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 006_20170209_atc_kenyan_court_rules_government_must_not_close_refugee_camp.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 007_20170209_atc_veteran_teaches_therapists_how_to_talk_about_gun_safety_when_suicides_a_risk.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 008_20170209_atc_soapmaker_dr_bronner_releases_posthumous_album_of_his_own_words.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 009_20170209_atc_short_term_rental_texas.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 010_20170209_atc_students_seek_to_recreate_ancient_beer_recipe_discovered_in_pottery_vessels.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 011_20170209_atc_kellyanne_conway_tells_americans_to_buy_ivanka_trumps_products.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 012_20170209_atc_syrian_torture_victim_speaks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 013_20170209_atc_jeff_sessions_takes_strong_anti-immigration_views_to_justice_department.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 014_20170209_atc_w_va_families_worry_about_access_to_addiction_treatment_under_trump.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 015_20170209_atc_white_house_courts_red_state_democrats_in_upcoming_legislative_battles.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 016_20170209_atc_in_divided_senate_maines_susan_collins_emerges_as_critical_voice.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 017_20170209_atc_as_trump_threatens_to_ditch_nafta_tijuana_residents_face_uncertainty.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 018_20170209_atc_while_others_saw_refugees_this_german_professor_saw_human_potential.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 019_20170209_atc_travel_ban_ruling_-_7pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 020_20170209_atc_travel_ban_ruling_-_8pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 021_20170209_atc_ferguson_ag.mp3\n",
      "[   INFO 2017-02-10 19:23] tagging segments\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/001_20170209_atc_general_requests_thousands_more_troops_to_break_afghanistan_stalemate.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/002_20170209_atc_yemen_requests_review_of_deadly_us_military_raid.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/003_20170209_atc_alabama_attorney_general_luther_strange_chosen_to_replace_jeff_sessions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/004_20170209_atc_west_bank_beit_el.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/005_20170209_atc_in_talks_with_trump_japans_shinzo_abe_will_seek_to_smooth_economic_tensions.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/006_20170209_atc_kenyan_court_rules_government_must_not_close_refugee_camp.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/007_20170209_atc_veteran_teaches_therapists_how_to_talk_about_gun_safety_when_suicides_a_risk.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/008_20170209_atc_soapmaker_dr_bronner_releases_posthumous_album_of_his_own_words.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/009_20170209_atc_short_term_rental_texas.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/010_20170209_atc_students_seek_to_recreate_ancient_beer_recipe_discovered_in_pottery_vessels.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/011_20170209_atc_kellyanne_conway_tells_americans_to_buy_ivanka_trumps_products.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/012_20170209_atc_syrian_torture_victim_speaks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/013_20170209_atc_jeff_sessions_takes_strong_anti-immigration_views_to_justice_department.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/014_20170209_atc_w_va_families_worry_about_access_to_addiction_treatment_under_trump.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/015_20170209_atc_white_house_courts_red_state_democrats_in_upcoming_legislative_battles.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/016_20170209_atc_in_divided_senate_maines_susan_collins_emerges_as_critical_voice.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/017_20170209_atc_as_trump_threatens_to_ditch_nafta_tijuana_residents_face_uncertainty.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/018_20170209_atc_while_others_saw_refugees_this_german_professor_saw_human_potential.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/019_20170209_atc_travel_ban_ruling_-_7pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/020_20170209_atc_travel_ban_ruling_-_8pm.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/All-Things-Considered/2017-02-09_ATCO/021_20170209_atc_ferguson_ag.mp3\n",
      "[  DEBUG 2017-02-10 19:23] ********** cleaning show: All Things Considered\n",
      "[  DEBUG 2017-02-10 19:23] keeping a maximum of 3 episodes\n",
      "[  DEBUG 2017-02-10 19:23] cleaning up stale shows for ALL THINGS CONSIDERED\n",
      "[  DEBUG 2017-02-10 19:23] searching path: ./output/All-Things-Considered/\n",
      "[  DEBUG 2017-02-10 19:23] previously downloaded episodes found: 7\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/All-Things-Considered/2017-01-28_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/All-Things-Considered/2017-01-29_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/All-Things-Considered/2017-01-30_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/All-Things-Considered/2017-02-05_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/All-Things-Considered/2017-01-28_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/All-Things-Considered/2017-01-28_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/All-Things-Considered/2017-01-28_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/All-Things-Considered/2017-01-29_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/All-Things-Considered/2017-01-29_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/All-Things-Considered/2017-01-29_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/All-Things-Considered/2017-01-30_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/All-Things-Considered/2017-01-30_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/All-Things-Considered/2017-01-30_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/All-Things-Considered/2017-02-05_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/All-Things-Considered/2017-02-05_ATCO\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/All-Things-Considered/2017-02-05_ATCO\n",
      "[   INFO 2017-02-10 19:23] downloding program: MORNING EDITION\n",
      "[  DEBUG 2017-02-10 19:23] checking for output directory: ./output/Morning-Edition/2017-02-10_MED/\n",
      "[  DEBUG 2017-02-10 19:23] output directory (./output/Morning-Edition/2017-02-10_MED/) not found\n",
      "[  DEBUG 2017-02-10 19:23] attempiting to create output directory\n",
      "[  DEBUG 2017-02-10 19:23] writing lockfile: ./output/Morning-Edition/2017-02-10_MED/.podcastdownload.lock\n",
      "[  DEBUG 2017-02-10 19:23] dryrun = False\n",
      "[  DEBUG 2017-02-10 19:23] <type 'bool'>\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_trump_travel_ban_still_on_hold_after_appeals_court_decision.mp3?orgId=1&topicId=1014&d=310&p=3&story=514458642&t=progseg&e=514458569&seg=1&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/001_20170210_me_trump_travel_ban_still_on_hold_after_appeals_court_decision.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_the_ethics_of_trump_hosting_japans_shinzo_abe_at_mar-a-lago.mp3?orgId=1&topicId=1014&d=308&p=3&story=514458649&t=progseg&e=514458569&seg=2&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/002_20170210_me_the_ethics_of_trump_hosting_japans_shinzo_abe_at_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_opposition_denounces_president_and_fights_break_out_in_south_african_parliament.mp3?orgId=1&topicId=1126&d=130&p=3&story=514458656&t=progseg&e=514458569&seg=3&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/003_20170210_me_opposition_denounces_president_and_fights_break_out_in_south_african_parliament.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_john_oliver_on_facts_donald_trump_and_the_supreme_court_for_dogs_.mp3?orgId=1&topicId=1138&d=289&p=3&story=514152562&t=progseg&e=514458569&seg=4&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/004_20170210_me_john_oliver_on_facts_donald_trump_and_the_supreme_court_for_dogs_.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_hr1_return_-_dg.mp3?orgId=1&topicId=1124&d=28&p=3&story=514458669&t=progseg&e=514458569&seg=5&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/005_20170210_me_hr1_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_voa_chief_on_the_future_of_the_news_service.mp3?orgId=1&topicId=1020&d=264&p=3&story=514458676&t=progseg&e=514458569&seg=6&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/006_20170210_me_voa_chief_on_the_future_of_the_news_service.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_us_bases_on_japanese_island_of_okinawa_have_long_been_contentious.mp3?orgId=1&topicId=1125&d=171&p=3&story=514458686&t=progseg&e=514458569&seg=7&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/007_20170210_me_us_bases_on_japanese_island_of_okinawa_have_long_been_contentious.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_trumps_possible_border_adjustment_tax_explained.mp3?orgId=1&topicId=1017&aggIds=94427042&d=213&p=3&story=514458693&t=progseg&e=514458569&seg=8&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/008_20170210_me_trumps_possible_border_adjustment_tax_explained.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_to_get_his_first_oscar_nod_justin_timberlake_had_to_act_like_a_troll.mp3?orgId=1&topicId=1105&d=425&p=3&story=514332025&t=progseg&e=514458569&seg=9&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/009_20170210_me_to_get_his_first_oscar_nod_justin_timberlake_had_to_act_like_a_troll.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_the_political_battles_ahead_over_remaining_trump_cabinet_picks.mp3?orgId=1&topicId=1014&d=393&p=3&story=514458700&t=progseg&e=514458569&seg=10&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/010_20170210_me_the_political_battles_ahead_over_remaining_trump_cabinet_picks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_self-driving_cars_could_ease_our_commutes_but_thatll_take_a_while.mp3?orgId=1&topicId=1019&d=222&p=3&story=514091049&t=progseg&e=514458569&seg=11&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/011_20170210_me_self-driving_cars_could_ease_our_commutes_but_thatll_take_a_while.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_fordham_university_report_examines_isis_prosecutions_in_the_us.mp3?orgId=1&topicId=1122&d=231&p=3&story=514458707&t=progseg&e=514458569&seg=12&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/012_20170210_me_fordham_university_report_examines_isis_prosecutions_in_the_us.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_a_romance_that_began_with_a_mistake.mp3?orgId=1&topicId=1022&aggIds=4516989&d=172&p=3&story=514299696&t=progseg&e=514458569&seg=13&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/013_20170210_me_a_romance_that_began_with_a_mistake.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_hr2_return_-_dg.mp3?orgId=1&topicId=1091&d=28&p=3&story=514458714&t=progseg&e=514458569&seg=14&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/014_20170210_me_hr2_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_japans_abe_to_spend_time_with_trump_at_the_white_and_mar-a-lago.mp3?orgId=1&topicId=1004&d=297&p=3&story=514458721&t=progseg&e=514458569&seg=15&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/015_20170210_me_japans_abe_to_spend_time_with_trump_at_the_white_and_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_brazilian_state_suffers_through_days_of_violence_during_police_strike.mp3?orgId=1&topicId=1127&d=137&p=3&story=514458734&t=progseg&e=514458569&seg=16&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/016_20170210_me_brazilian_state_suffers_through_days_of_violence_during_police_strike.mp3\n",
      "[  DEBUG 2017-02-10 19:23] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170210_me_tripadvisor_backs_appeals_court_refusal_to_reinstate_travel_ban.mp3?orgId=1&topicId=1006&d=222&p=3&story=514458744&t=progseg&e=514458569&seg=17&siteplayer=true\n",
      "[   INFO 2017-02-10 19:23] writing file to ./output/Morning-Edition/2017-02-10_MED/017_20170210_me_tripadvisor_backs_appeals_court_refusal_to_reinstate_travel_ban.mp3\n",
      "[  DEBUG 2017-02-10 19:23] opening log file: ./output/download.log\n",
      "[   INFO 2017-02-10 19:23] opening m3u playlist: 2017-02-10-MORNING-EDITION.m3u\n",
      "[  DEBUG 2017-02-10 19:23] writing segments to: 2017-02-10-MORNING-EDITION.m3u\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 001_20170210_me_trump_travel_ban_still_on_hold_after_appeals_court_decision.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 002_20170210_me_the_ethics_of_trump_hosting_japans_shinzo_abe_at_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 003_20170210_me_opposition_denounces_president_and_fights_break_out_in_south_african_parliament.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 004_20170210_me_john_oliver_on_facts_donald_trump_and_the_supreme_court_for_dogs_.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 005_20170210_me_hr1_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 006_20170210_me_voa_chief_on_the_future_of_the_news_service.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 007_20170210_me_us_bases_on_japanese_island_of_okinawa_have_long_been_contentious.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 008_20170210_me_trumps_possible_border_adjustment_tax_explained.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 009_20170210_me_to_get_his_first_oscar_nod_justin_timberlake_had_to_act_like_a_troll.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 010_20170210_me_the_political_battles_ahead_over_remaining_trump_cabinet_picks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 011_20170210_me_self-driving_cars_could_ease_our_commutes_but_thatll_take_a_while.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 012_20170210_me_fordham_university_report_examines_isis_prosecutions_in_the_us.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 013_20170210_me_a_romance_that_began_with_a_mistake.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 014_20170210_me_hr2_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 015_20170210_me_japans_abe_to_spend_time_with_trump_at_the_white_and_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 016_20170210_me_brazilian_state_suffers_through_days_of_violence_during_police_strike.mp3\n",
      "[  DEBUG 2017-02-10 19:23] writing segment to m3u file: 017_20170210_me_tripadvisor_backs_appeals_court_refusal_to_reinstate_travel_ban.mp3\n",
      "[   INFO 2017-02-10 19:23] tagging segments\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/001_20170210_me_trump_travel_ban_still_on_hold_after_appeals_court_decision.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/002_20170210_me_the_ethics_of_trump_hosting_japans_shinzo_abe_at_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/003_20170210_me_opposition_denounces_president_and_fights_break_out_in_south_african_parliament.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/004_20170210_me_john_oliver_on_facts_donald_trump_and_the_supreme_court_for_dogs_.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/005_20170210_me_hr1_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/006_20170210_me_voa_chief_on_the_future_of_the_news_service.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/007_20170210_me_us_bases_on_japanese_island_of_okinawa_have_long_been_contentious.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/008_20170210_me_trumps_possible_border_adjustment_tax_explained.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/009_20170210_me_to_get_his_first_oscar_nod_justin_timberlake_had_to_act_like_a_troll.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/010_20170210_me_the_political_battles_ahead_over_remaining_trump_cabinet_picks.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/011_20170210_me_self-driving_cars_could_ease_our_commutes_but_thatll_take_a_while.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/012_20170210_me_fordham_university_report_examines_isis_prosecutions_in_the_us.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/013_20170210_me_a_romance_that_began_with_a_mistake.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/014_20170210_me_hr2_return_-_dg.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/015_20170210_me_japans_abe_to_spend_time_with_trump_at_the_white_and_mar-a-lago.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/016_20170210_me_brazilian_state_suffers_through_days_of_violence_during_police_strike.mp3\n",
      "[  DEBUG 2017-02-10 19:23] tagging ./output/Morning-Edition/2017-02-10_MED/017_20170210_me_tripadvisor_backs_appeals_court_refusal_to_reinstate_travel_ban.mp3\n",
      "[  DEBUG 2017-02-10 19:23] ********** cleaning show: Morning Edition\n",
      "[  DEBUG 2017-02-10 19:23] keeping a maximum of 3 episodes\n",
      "[  DEBUG 2017-02-10 19:23] cleaning up stale shows for MORNING EDITION\n",
      "[  DEBUG 2017-02-10 19:23] searching path: ./output/Morning-Edition/\n",
      "[  DEBUG 2017-02-10 19:23] previously downloaded episodes found: 12\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-11_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-12_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-13_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-16_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-27_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-10 19:23] flagged for deletion: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-11_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-11_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-11_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-12_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-12_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-12_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-13_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-13_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-13_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-16_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-16_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-16_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-27_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-27_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-27_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-30_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-01-31_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-02-01_MED\n",
      "[  DEBUG 2017-02-10 19:23] attempting to clean episode files in: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-10 19:23] found lock file in path: ./output/Morning-Edition/2017-02-03_MED\n",
      "[  DEBUG 2017-02-10 19:23] deleting path: ./output/Morning-Edition/2017-02-03_MED\n"
     ]
    }
   ],
   "source": [
    "foo = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = NPREpisode()\n",
    "dir(foo)\n",
    "print foo._slugify('Wait, Wait...Don\\'t tell me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = datetime.date(datetime.now(pytz.timezone('EST')))\n",
    "\n",
    "print foo.isoweekday()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nowTime = datetime.time(datetime.now(pytz.timezone('EST')))\n",
    "nowDate = datetime.date(datetime.now(pytz.timezone('EST')))\n",
    "print nowDate.isoweekday()\n",
    "print dir(nowDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynpr = NPREpisode()\n",
    "mynpr.outputBasePath = './output/'\n",
    "mynpr.setOutputPath('foo')\n",
    "#mynpr.programURL = 'http://www.npr.org/programs/all-things-considered'\n",
    "mynpr.programURL = 'http://www.npr.org/programs/morning-edition/'\n",
    "#mynpr.programURL = 'http://www.npr.org/programs/wait-wait-dont-tell-me/'\n",
    "\n",
    "mynpr.getepisode_HTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeFMT = '%H:%M'\n",
    "defaultTime = '23:59'\n",
    "if 'updatetime' in self.options:\n",
    "    # sanitize the time string datetime.time(datetime.strptime('13:55', timeFMT))\n",
    "    try:\n",
    "        self.updateTime = datetime.time(datetime.strptime(re.sub('[^0-9\\:]+', '', self.options['updatetime']), timeFMT))\n",
    "    except ValueError as e:\n",
    "        logging.error('bad updatetime time format: %s', self.options['updatetime'])\n",
    "        logging.error('setting updatetime to: %s', defaultTime)\n",
    "        self.updateTime = datetime.time(datetime.strptime(defaultTime, timeFMT))    \n",
    "else:\n",
    "    self.updateTime = '19:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainbkup(argv=None):\n",
    "    logging.basicConfig(filename=programName+'.log', \n",
    "                        level=logging.DEBUG,\n",
    "                        format='%(levelname)s %(asctime)s %(message)s', \n",
    "                        datefmt='%d %b %Y %H:%M:%S')\n",
    "    \n",
    "    logging.Logger.addHandler(terminalMSG)\n",
    "    logging.info('******started log*******')\n",
    "    \n",
    "    # default configuration file\n",
    "    cfgFile = 'settings.ini'\n",
    "    \n",
    "    # list of shows found in configuration file\n",
    "    shows = []\n",
    "    \n",
    "    \n",
    "    # load non-standard python libraries\n",
    "    loadModules()\n",
    "    \n",
    "    if argv is None:\n",
    "        arv = sys.argv\n",
    "    \n",
    "        # set up a command line parser to deal with everything on the command line\n",
    "\n",
    "    # disable -h for help so the second parser can deal with this\n",
    "    # http://stackoverflow.com/questions/3609852/which-is-the-best-way-to-allow-configuration-options-be-overridden-at-the-comman\n",
    "    cmdlineParser = argparse.ArgumentParser(description = __doc__, \n",
    "                                           formatter_class = argparse.RawDescriptionHelpFormatter,\n",
    "                                          add_help = False)\n",
    "    # handle the jupyter -f option while developing in jupyter\n",
    "    #cmdlineParser.add_argument('-f', '--fconfig', help='fake config file', action='store')\n",
    "    # set the configuration file\n",
    "    cmdlineParser.add_argument('-c', '--configfile', help='configuration file', metavar='FILE',\n",
    "                              action='store', default=cfgFile)\n",
    "    # determine if this is a dry run or not\n",
    "    cmdlineParser.add_argument('-d', '--dryrun', help='preform a dry-run with no downloads',\n",
    "                              action='store_true', default=False)\n",
    "    \n",
    "    # reamining arguments stored in unknownArgs\n",
    "    args, unknownArgs = cmdlineParser.parse_known_args()\n",
    "    \n",
    "    # parse the configuration file\n",
    "    defaults = {}\n",
    "    # create a configuration file parser\n",
    "    configParser = ConfigParser.SafeConfigParser()\n",
    "    # read the config file for the \"defaults\" section\n",
    "    logging.debug('reading configuraiton file: %s', args.configfile)\n",
    "    configParser.read(args.configfile)\n",
    "    # pull the Defaults section from the ini\n",
    "    defaults.update(dict(configParser.items('Defaults')))\n",
    "    \n",
    "    # merge the command line with teh config file options\n",
    "    parser = argparse.ArgumentParser(parents=[cmdlineParser])\n",
    "    \n",
    "    parser.set_defaults(**defaults)\n",
    "    \n",
    "    # search for all the show sections in the configuration file \n",
    "    sectionIndex = 0\n",
    "    for section in configParser.sections():\n",
    "        # find all show descriptiors\n",
    "        if '%' in section:\n",
    "            logging.debug('found show: %s', section)\n",
    "            #shows.append(dict(configParser.items(section)))\n",
    "            shows.append(showConfig((dict(configParser.items(section)))))\n",
    "            shows[sectionIndex].verifyConfig()\n",
    "            # if no name is set, use the show descriptor \n",
    "            if not 'showname' in shows[sectionIndex].options:\n",
    "                shows[sectionIndex].showName = str(section).replace('%', '')\n",
    "                logging.warning('No show name found in configuration file\\nusing section name: %s', shows[sectionIndex].showName)\n",
    "            sectionIndex += 1\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(shows) == 0:\n",
    "        logging.fatal('fatal error - no shows found in configuration file: %s', args.configfile)\n",
    "        exit(1)\n",
    "    for each in shows:\n",
    "        print each.showName\n",
    "        print each.updateTime, each.timezone\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myOpts = {'updatedays': '1, 2, 3', 'updatetime': '199:00xasdf99', 'programs': '2', 'url': 'http://www.npr.org/programs/all-things-considered/', 'fetchmethod': 'NPR_HTML', 'timezone': 'EST', 'showname': 'All Things Considered'}\n",
    "myConfig = showConfig(myOpts)\n",
    "myConfig.verifyConfig()\n",
    "myConfig.updateDays\n",
    "print myConfig.showName\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now_utc = datetime.now(pytz.timezone('UTC'))\n",
    "#now_east = now_utc.astimezone(pytz.timezone('US/Eastern'))\n",
    "now_east = now_utc.astimezone(pytz.timezone('EST'))\n",
    "print now_east\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeFMT = '%H:%M'\n",
    "foo = datetime.time(datetime.strptime('13:55', timeFMT))\n",
    "dir(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mynpr.showDate + '-' +mynpr.name.replace(' ', '_') + '.m3u'\n",
    "mynpr.setM3U(mynpr.showDate + '-' + mynpr.name)\n",
    "#mynpr.setM3U('foobar')\n",
    "print mynpr.m3u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynpr.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynpr.writeM3U()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynpr.writeM3U()\n",
    "mynpr.logDownload()\n",
    "mynpr.tagSegments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mynpr.tagSegments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = 'a'\n",
    "if isinstance(foo, list):\n",
    "    print 'yup'\n",
    "else: \n",
    "    print 'nope'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
