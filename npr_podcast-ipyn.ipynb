{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright 2016 Aaron ciuffo\n",
    "\n",
    "version = '''NPR Podcast Downloader V5.0\n",
    "\n",
    "by Aaron Ciuffo (txoof.com)\n",
    "released without warranty under GPLV3:\n",
    "http://www.gnu.org/licenses/gpl-3.0.html\n",
    "Please don't sue me.\n",
    "'''\n",
    "\n",
    "programName = 'podcastdownload'\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime # for time stuff\n",
    "import pytz\n",
    "import logging # logging library\n",
    "from urllib2 import urlopen # standard library for interfacing with web resources\n",
    "from urllib2 import URLError\n",
    "import re # regular expressions\n",
    "import json # handle JSON objects\n",
    "import os # Opperating System interface \n",
    "import sys # internal opperations including a list of imported modules\n",
    "import fnmatch # used by cleanup method in Episode\n",
    "import glob # used by m3u method - consider replacing with some other library\n",
    "import shutil # used by cleanup method\n",
    "import argparse # parse command line arguments\n",
    "import ConfigParser # parse config files\n",
    "from random import SystemRandom \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "## def main()\n",
    " * General rewrite and cleanup \n",
    "  - Move variables to one place\n",
    "  - reconsider some of the messier loops\n",
    "  \n",
    "## Testing\n",
    " * Test command line\n",
    "  - test all command line options \n",
    "  - test all configuration options (remove options, sections, and otherwise break the config file) \n",
    "\n",
    "## Downloading\n",
    " * consider chainging import from urllib2; 2x import because of URLError AND urlopen\n",
    "\n",
    "## Configuration\n",
    " * Add option to generate configuration file\n",
    " * remove % in front of section names ?\n",
    " * change name from 'Default' to 'Main'\n",
    " * change default name of configuration file to ~/.programname.ini\n",
    "\n",
    "\n",
    "## Completed\n",
    " * Adapt NPREpisode object to use new class attributes for output paths\n",
    " * complete the cleanup method\n",
    " * remove any 'stale' episodes\n",
    " * add a check to see if a program is already downloaded (maybe look for m3u) or at the download log\n",
    " * -v overrides configuration file\n",
    " * remove download logging - this is not necessary; it's a holdover from previous versions\n",
    " * reorganize configuration options to allow commandline to influence logging  \n",
    "     - only log to a file if a logfile is specified\n",
    "     - add support for setting log from configuration file, setting logging level\n",
    " * consider removing all the day and time checking for episodes; it's not relevant for HTML queries\n",
    "     - the day and time checking may be needed for API queries if this is implemented\n",
    " * consider removing all the day and time checking for episodes; it's not relevant for HTML queries\n",
    "     - consider removing date and time check from showConfig class\n",
    " * implement User-Agent in urllib2 request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadModules():\n",
    "    '''load non standard python modules'''\n",
    "    import logging\n",
    "    logging.basicConfig()\n",
    "    logging.debug('loading module: requests')\n",
    "    try:\n",
    "        global requests\n",
    "        import requests\n",
    "    except Exception as e:\n",
    "        logging.critical('Fatal Error\\nFailed to load module: requests\\n%s', e)\n",
    "        logging.critical('Please install requests module: http://docs.python-requests.org/')\n",
    "        exit(2)\n",
    "        return(False)\n",
    "\n",
    "    logging.debug('loading module: mutagen.mp3')\n",
    "    # create a global list of all the taggers available\n",
    "    global taggers\n",
    "    taggers = {}\n",
    "    try:\n",
    "        global MP3\n",
    "        from mutagen.mp3 import EasyMP3 as MP3\n",
    "    except Exception, e:\n",
    "        logging.critical('Failed to load module: mutagen.mp3\\n%s', e)\n",
    "        logging.critical('mp3 tagging may not be available')    \n",
    "    taggers['mp3'] = MP3\n",
    "\n",
    "    \n",
    "    logging.debug('loading module: mutagen.mp4')\n",
    "    try:\n",
    "        global MP4\n",
    "        from mutagen.mp4 import MP4\n",
    "    except Exception, e:\n",
    "        logging.critical('Failed to load module: mutagen.mp4\\n%s', e)\n",
    "        logging.critical('mp4 tagging may not be available')    \n",
    "    taggers['mp4'] = MP4\n",
    "\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def div(num = 10, char = '*'):\n",
    "    '''\n",
    "    returns a multiple copies of a passed string\n",
    "    Args:\n",
    "        num (int): number of times to repeat string\n",
    "        char (string): characters to repeat\n",
    "    Returns:\n",
    "        char*n (string)\n",
    "    '''\n",
    "    if isinstance(num, int):\n",
    "        return(str(str(char)*num))\n",
    "    else:\n",
    "        return(str(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Episode():\n",
    "    '''Podcast episode object'''\n",
    "\n",
    "    def __init__(self, name = 'No Name', programURL = 'undef', showDate = None, outputBasePath = './', \n",
    "                 m3u = 'playlist.m3u', downloadLog = 'download.log', keep = 3):\n",
    "        '''\n",
    "        Args:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "            keep(int): maximumnumber of programs to keep\n",
    "            \n",
    "        Attributes:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            segments (list): Segment() objects to be downloaded\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            outputShowPath (str): path within outputBasePath - slugified version of name\n",
    "            outputPath (str): path within outputShowPath - set to outputShowPath by default\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "            keep (int): maximum number of programs to keep\n",
    "        '''\n",
    "        self.name = name # str\n",
    "        self.programURL = programURL # str\n",
    "        self.segments = [] # list\n",
    "        self.showDate = showDate # str\n",
    "        self.outputBasePath = self._slash(outputBasePath) # str\n",
    "        self.outputShowPath = self.outputBasePath + self._slash(self._slugify(self.name))\n",
    "        self.outputPath = self.outputShowPath\n",
    "        self.m3u = m3u\n",
    "        self.downloadLog = downloadLog  \n",
    "        self.keep = keep\n",
    "    \n",
    "    def attributes(self, display = None):\n",
    "        '''\n",
    "        method to show relevant attributes of\n",
    "        Args:\n",
    "            display (list): list of specific attributes to display\n",
    "        Retruns:\n",
    "            Specific attributes\n",
    "        '''\n",
    "        if isinstance(display, list):\n",
    "            display = display\n",
    "        else:\n",
    "            display = ['name', 'programURL', 'showDate', 'outputBasePath', 'outputShowPath', 'outputPath', \n",
    "                   'm3u', 'downloadLog', 'keep']\n",
    "        attributes = {}\n",
    "        for key in self.__dict__:\n",
    "            if (key in display) and (key in self.__dict__):\n",
    "                attributes[key] = self.__dict__[key]\n",
    "        \n",
    "        return(attributes)\n",
    "                \n",
    "        \n",
    "    \n",
    "    def _slugify(self, value):\n",
    "        \"\"\"\n",
    "        Normalizes string, converts to lowercase, removes non-alpha characters,\n",
    "        and converts spaces to hyphens.\n",
    "\n",
    "        From Django's \"django/template/defaultfilters.py\".\n",
    "        Args:\n",
    "            value (str): string to be normalized for use with a filename\n",
    "        \n",
    "        Returns:\n",
    "            unicode: sluggified string\n",
    "        \"\"\"\n",
    "        _slugify_strip_re = re.compile(r'[^\\w\\s-]')\n",
    "        _slugify_hyphenate_re = re.compile(r'[-\\s]+')\n",
    "\n",
    "        import unicodedata\n",
    "        if not isinstance(value, unicode):\n",
    "            value = unicode(value)\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore')\n",
    "        value = unicode(_slugify_strip_re.sub('', value).strip())\n",
    "        return _slugify_hyphenate_re.sub('-', value)\n",
    "\n",
    "    def _slash(self, value):\n",
    "        '''\n",
    "        Ensures path has a trailing slash\n",
    "        \n",
    "        Args:\n",
    "            value (str): string to check and modify\n",
    "        \n",
    "        Returns:\n",
    "            value (str): string with trailing slash\n",
    "            \n",
    "        '''\n",
    "        if not re.match('.*\\/$', value):\n",
    "            logging.debug('adding trailing slash to path: %s', value)\n",
    "            return(value + '/')\n",
    "        else:\n",
    "            return(value)\n",
    "    \n",
    "    def setOutputPath(self, outputShowPath = None, outputEpisodePath = None):\n",
    "        '''\n",
    "        Method to update the output paths\n",
    "        Args:\n",
    "            outputShowPath (str): path within the outputBasePath\n",
    "            outputEpisodePath (str): path within outputShowPath\n",
    "        Returns:\n",
    "            outputEpisodePath (str)\n",
    "        '''\n",
    "        if outputShowPath:\n",
    "            self.outputShowPath = self._slash(self.outputBasePath) + self._slash(outputShowPath)\n",
    "        \n",
    "        if outputEpisodePath:\n",
    "            self.outputPath = self._slash(self.outputShowPath) + self._slash(outputEpisodePath)\n",
    "        else:\n",
    "            self.outputPath = self.outputShowPath\n",
    "            \n",
    "        return(self.outputPath)\n",
    "    \n",
    "    def setM3U(self, name = 'playlist'):\n",
    "        '''\n",
    "        Update the m3u file name\n",
    "        Args:\n",
    "            name (str): filename for the m3u\n",
    "        '''\n",
    "        self.m3u = self._slugify(name) + '.m3u'\n",
    "        return(True)\n",
    "    \n",
    "    def writeM3U(self, filename = False):\n",
    "        '''\n",
    "        Write M3U playlist for the episode in the root of the output directory\n",
    "        Args:\n",
    "            filename (str): path to output filename\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        \n",
    "        logging.info('opening m3u playlist: %s', self.m3u)\n",
    "        if filename:\n",
    "            self.setm3u(filename)\n",
    "        \n",
    "        try:\n",
    "            #m3ufile = open(self.outputBasePath + self.m3u, 'w')\n",
    "            m3ufile = open(self._slash(self.outputPath) + self.m3u, 'w')\n",
    "        except Exception as e:\n",
    "            logging.error('could not open m3u file: %s\\n%s', self.m3u, e)\n",
    "            return(False)\n",
    "        logging.debug('writing segments to: %s', self.m3u)\n",
    "        # recurse all the segments \n",
    "        for segment in self.segments:\n",
    "            # if it was successfully downloaded write it to the m3u file\n",
    "            if segment.downloaded:\n",
    "                logging.debug('writing segment to m3u file: %s', segment.filename)\n",
    "                try:\n",
    "                    #m3ufile.write(self.outputPath + segment.filename + '\\n')\n",
    "                    m3ufile.write(segment.filename + '\\n')\n",
    "                except Exception as e:\n",
    "                    logging.error('could not write to: %s\\n%s', self.m3u, e)\n",
    "                    logging.error('halting m3u writing')\n",
    "                    return(False)\n",
    "        # cleanup\n",
    "        try:\n",
    "            m3ufile.close()\n",
    "        except Exception as e:\n",
    "            logging.error('could not close m3u file: %s\\n%s', self.m3u, e)\n",
    "            return(False)\n",
    "        \n",
    "        return(True)\n",
    "    \n",
    "    \n",
    "    def download(self, dryrun = False, timeout = 5, useragent = ''):\n",
    "        '''\n",
    "        Download all segments in self.segment into self.outputPath\n",
    "        Args:\n",
    "            dryrun (bool): When true do all other steps, but do not download and return: False\n",
    "            timeout (real): time in seconds to wait for a download to complete before timing out\n",
    "        \n",
    "        Returns: \n",
    "            bool: True for successful download of all segments\n",
    "        '''\n",
    "        \n",
    "        success = True\n",
    "        lockfile = self.outputPath + '.' + programName + '.lock'\n",
    "        logging.info('downloading program: %s', self.name)\n",
    "        \n",
    "        # check for output path\n",
    "        logging.debug('checking for output directory: %s', self.outputPath)\n",
    "        if not os.path.isdir(self.outputPath):\n",
    "            logging.debug('output directory (%s) not found', self.outputPath)\n",
    "            logging.debug('attempiting to create output directory')\n",
    "            try:\n",
    "                os.makedirs(self.outputPath)\n",
    "            except Exception as e:\n",
    "                logging.error('could not create outputpath for this episdoe at: %s\\n%s', self.outputPath, e)\n",
    "                logging.error('download failed')\n",
    "                return(False)\n",
    "            \n",
    "            # make a 'lock file' in the folder to help with cleanup later  \n",
    "            logging.debug('writing lockfile: %s', lockfile)\n",
    "            try:\n",
    "                with open(lockfile, 'a'):\n",
    "                    os.utime(lockfile, None)\n",
    "            except Exception as e:\n",
    "                logging.error('could not create lockfile: %s', lockfile)\n",
    "                logging.error('file error: %s', e)\n",
    "        \n",
    "        # check for existing m3u files; stop downloading if it exists\n",
    "        if len(glob.glob(self.outputPath + '/*.m3u')) > 0:\n",
    "            logging.info('episode previously downloaded; skipping')\n",
    "            return(False)\n",
    "        \n",
    "        logging.debug('dryrun = %s', dryrun)\n",
    "        if dryrun:\n",
    "            logging.info('downloads will be simulated')\n",
    "        for segment in self.segments:\n",
    "            # update the path for the current segment\n",
    "            filePath = self.outputPath + segment.filename\n",
    "            logging.debug('downloading %s', segment.audioURL)\n",
    "            if not dryrun:\n",
    "                try:\n",
    "#                     audioFile = urlopen(segment.audioURL, timeout = timeout, \n",
    "#                           data = {'User-Agent' : useragent}).read()\n",
    "                    audioFile = urlopen(segment.audioURL, timeout = timeout).read()\n",
    "                except URLError as e:\n",
    "                    logging.warning('could not download segment number: %s', segment.number)\n",
    "                    logging.warning('error: %s; timeout: %s', e, timeout)\n",
    "                    success = False\n",
    "                    continue\n",
    "            \n",
    "            logging.info('writing file to %s', filePath)\n",
    "            \n",
    "            if not dryrun:\n",
    "                try:\n",
    "                    with open(filePath, 'wb') as code:\n",
    "                        code.write(audioFile)\n",
    "                        # record if the writing was successful\n",
    "                        segment.downloaded = True\n",
    "                except Exception as e:\n",
    "                    logging.warning('could not write segment number %s to %s\\nerrors follow', segment.number, filePath)\n",
    "                    logging.warning(e)\n",
    "                    success = False\n",
    "                    continue\n",
    "            else:\n",
    "                # record succsessful downloading of all segments when doing a dry run\n",
    "                segment.downloaded = True\n",
    "                # Dry runs return \"false\"\n",
    "                success = False\n",
    "            \n",
    "        \n",
    "        # This is a holdover from a previous version; it is not really needed\n",
    "        #self.logDownload()\n",
    "            \n",
    "        return(success)       \n",
    "            \n",
    "    def logDownload(self):\n",
    "        '''\n",
    "        Holdover from a previous version as a method for tracking files that were downloaded; no longer needed\n",
    "        Log successfully downloaded episodes\n",
    "        Args:\n",
    "        Returns: \n",
    "            bool: True\n",
    "        '''\n",
    "        logFile = self.outputBasePath + self.downloadLog\n",
    "        \n",
    "        logging.debug('opening log file: %s', logFile)\n",
    "        try:\n",
    "            f = open(logFile, 'a')\n",
    "        except Exception as e:\n",
    "            logging.error('could not open log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        try: \n",
    "            f.write(self.outputPath + '\\n')\n",
    "        except Exception as e:\n",
    "            logging.error('could not write to log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        try:\n",
    "            f.close()\n",
    "        except Exception as e:\n",
    "            logging.error('could not close log file: %s\\n%s', logFile, e)\n",
    "            return(False)\n",
    "        \n",
    "        return(True)\n",
    "            \n",
    "    \n",
    "    def addSegment(self, segment):\n",
    "        '''\n",
    "        Add a downloadable segment to the segment list\n",
    "        Args:\n",
    "            segment (Segment): Segment() object containing information\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        self.segments.append(segment)\n",
    "        return(True)\n",
    "        \n",
    "            \n",
    "    def tagSegments(self):\n",
    "        '''\n",
    "        Tag all downloaded segments\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "            bool: True\n",
    "        '''\n",
    "        logging.info('tagging segments')\n",
    "        for segment in self.segments:\n",
    "            filename = self.outputPath + segment.filename\n",
    "            try:\n",
    "                filetype = re.search('\\.(\\w+$)', filename).group(1)\n",
    "            except:\n",
    "                filetype = None\n",
    "\n",
    "            if filetype.lower() in taggers:\n",
    "                logging.debug('tagging %s', filename)\n",
    "                myTagger = taggers[filetype]\n",
    "                audio = myTagger(filename)\n",
    "                \n",
    "                audio['title'] = segment.title\n",
    "                audio['tracknumber'] = str(segment.number)\n",
    "                audio['album'] = segment.programName\n",
    "                \n",
    "                try:\n",
    "                    audio.save()\n",
    "                except Exception as e:\n",
    "                    logging.error('could not write tags for: %s\\n%s', filename, e)        \n",
    "            else:\n",
    "                logging.info('could not tag, unknown filetype: %s', filename) \n",
    "                \n",
    "    def cleanUp(self, dryrun = False, lockfile = '*.lock', keep = None):\n",
    "        '''\n",
    "        Remove stale episodes, keeping at maximum self.keep episodes\n",
    "\n",
    "        Args:\n",
    "            dryrun (bool): when true, do not actually delete anything\n",
    "            lockfile (str): lockfile pattern glob to use when searching for lockfiles; default:*.lock\n",
    "            keep (int): maximum number of episodes to keep\n",
    "        Returns:\n",
    "            removed (list): removed paths\n",
    "        '''\n",
    "      \n",
    "        if keep:\n",
    "            self.keep = keep\n",
    "        if self.keep <= 0:\n",
    "            self.keep = 1\n",
    "            \n",
    "        logging.info('cleaning up stale shows for %s', self.name)\n",
    "        if not isinstance(self.keep, int):\n",
    "            logging.error('%s is not an integer: keep')\n",
    "        logging.info('keeping a maximum of %s shows', self.keep)\n",
    "        # candididate directories that contain lockfiles for deletion\n",
    "        matchdir = {}\n",
    "        logging.debug('searching path: %s', self.outputShowPath)\n",
    "        for root, dirnames, filenames in os.walk(self.outputShowPath):\n",
    "            logging.debug('%s', root)\n",
    "            for filename in fnmatch.filter(filenames, lockfile):\n",
    "                logging.debug('      %s', filename)\n",
    "                matchdir[root] = filename\n",
    "        \n",
    "        logging.debug('previously downloaded episodes found: %s', len(matchdir))\n",
    "        # files to delete\n",
    "        delete = []\n",
    "        \n",
    "        # files successfully deleted:\n",
    "        removed = []\n",
    "        for directory in range(0, len(sorted(matchdir))-self.keep):\n",
    "            logging.debug('flagged for deletion: %s', sorted(matchdir)[directory])\n",
    "            delete.append(sorted(matchdir)[directory])\n",
    "        \n",
    "        for key, val in enumerate(delete):\n",
    "            lockfile = os.path.join(delete[key], matchdir[delete[key]])\n",
    "            logging.debug('attempting to clean episode files in: %s', delete[key])\n",
    "            # double check that a *.lock file exists before attempting a delete\n",
    "            if os.path.isfile(lockfile):\n",
    "                logging.debug('found lock file in path: %s', delete[key])\n",
    "\n",
    "                if dryrun:\n",
    "                    logging.info('dryrun: simulating deletion (nothing will be removed)')\n",
    "                else:\n",
    "                    logging.debug('deleting path: %s\\n', delete[key])\n",
    "                    try:\n",
    "                        shutil.rmtree(delete[key])\n",
    "                        # record those paths removed\n",
    "                        removed.append(delete[key])\n",
    "                    except OSError as e:\n",
    "                        logging.error('could not delete path: %s', e)\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                logging.warn('discovered missing lock file when attempting cleanup: %s', lockfile)\n",
    "                logging.warn('manual deletion required: %s', delete[key])\n",
    "                logging.warn('skipping path: %s\\n', delete[key])\n",
    "\n",
    "        return(removed)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NPREpisode(Episode, object):\n",
    "    '''NPR program episode object\n",
    "        Args:\n",
    "            name (str): name of episode/podcast\n",
    "            programURL (str): Index URL containing list of files to download\n",
    "            showDate (str): date of episode\n",
    "            outputBasePath (str): base path to use for output of files (default is ./)\n",
    "            m3u (str): m3u playlist filename\n",
    "            downloadLog (str): download log filename\n",
    "            jsonData \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, name = 'unknown', programURL = None, outputBasePath = './', m3u ='playlist.m3u', \n",
    "                 downloadLog = 'download.log', keep = 3):\n",
    "        super(NPREpisode, self).__init__(name = name, programURL = programURL, outputBasePath = outputBasePath, \n",
    "                                         m3u = m3u, downloadLog = downloadLog, keep = keep)\n",
    "        self.jsonData = None\n",
    "\n",
    "    def recentEpisodes(self):\n",
    "        '''Identify the most recent episodes\n",
    "        Not yet implemented\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def getepisode_API():\n",
    "        '''\n",
    "        Use the NPR API to get a list of episodes\n",
    "        Not yet implemented\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def getepisode_HTML(self):\n",
    "        '''\n",
    "        Scrape the HTML for JSON containing the date segment and title information\n",
    "        Attributes set here:\n",
    "            self.jsonData (json obj) - JSON listing of episodes from NPR\n",
    "            self.showDate (str) - YYYY-MM-DD formatted string\n",
    "            self.name (str) - human readable show name \n",
    "            self.segments (:obj: Segment) - episode segments are populated and added\n",
    "\n",
    "        Returns: \n",
    "            bool: True if episode information is scraped from the HTML, False otherwise\n",
    "        '''\n",
    "        \n",
    "        logging.debug('fetching episode info via HTML method')\n",
    "        logging.debug('source: %s' % self.programURL)\n",
    "        \n",
    "        # search terms hardcoded here\n",
    "        search_PlayAll = \"<b.*data-play-all='({.*})'><\\/b>\" #re search string for JSON data in program HTML\n",
    "        search_FileName = \"(^[\\s|\\w|\\.|'|-]*)\\[?|$]\" #(anySpaces OR anyWords OR anyPeriod OR any' OR any-)? OR EOL\n",
    "        search_showDate = \"datetime=\\\"(\\d{4}-\\d{2}-\\d{2})\" #re search for show date\n",
    "               \n",
    "        \n",
    "        # variables defined here\n",
    "        filename = '' # extracted filename for each segment\n",
    "        \n",
    "        # add an extension to help differentiate between episodes; set to epoch seconds to prevent clobbering\n",
    "        # if no valid extension is set elsewhere\n",
    "        output_extension = int((datetime.now() - datetime.utcfromtimestamp(0)).total_seconds())\n",
    "        \n",
    "       \n",
    "        try: # fetch the full show HTML\n",
    "            programHTML = urlopen(self.programURL).read()\n",
    "        except Exception as e:\n",
    "            logging.warning('could not fetch episode information from %s' % self.programURL)\n",
    "            logging.error(e)\n",
    "            return(False)\n",
    "        logging.debug('HTML retrieved successfully')\n",
    "        \n",
    "        # find the show date and record it \n",
    "        self.showDate = re.search(search_showDate, programHTML).group(1)\n",
    "        \n",
    "        if len(self.showDate) < 1:\n",
    "            logging.warning('no valid showDate found')\n",
    "        else: logging.debug('show date: %s', self.showDate)\n",
    "        \n",
    "        try: # find the JSON program data\n",
    "            self.jsonData = json.loads(re.search(search_PlayAll, programHTML).group(1))\n",
    "        except Exception as e:\n",
    "            logging.error('no valid JSON episode listing found in HTML from %s', self.programURL)\n",
    "            logging.error(e)\n",
    "            return(False)\n",
    "        \n",
    "        # check that some JSON data was found - not terribly robust\n",
    "        if len(self.jsonData['audioData']) > 1:\n",
    "            logging.debug('JSON program information found for %s', self.jsonData['audioData'][0]['program'].upper())\n",
    "            logging.debug('setting name to: %s', self.name)\n",
    "            self.name = self.jsonData['audioData'][0]['program'].upper() # set the episode name\n",
    "            logging.debug('segments found: %s', len(self.jsonData['audioData']))\n",
    "        else:\n",
    "            logging.warn('no valid audioData found in JSON object for this program')\n",
    "            return(False)\n",
    "        \n",
    "        # grab the first character of each word in the program name; grab the last two characters of the last word\n",
    "        if len(self.name) > 0:\n",
    "            short_name = '_'\n",
    "            output_extension = '_'\n",
    "            for each, val in enumerate(self.name.split(' ')):\n",
    "                if each + 1 >= len(self.name.split(' ')):\n",
    "                    char = 2\n",
    "                else: \n",
    "                    char = 1\n",
    "                output_extension = output_extension + val[:char]\n",
    "                short_name = short_name + val[:char]\n",
    "\n",
    "        # create a sub directory within the output path\n",
    "        self.setOutputPath(outputEpisodePath = self.showDate + short_name) \n",
    "        logging.debug('output path set to: %s', self.outputPath)\n",
    "        \n",
    "        #set m3u name\n",
    "        self.setM3U(self.showDate + '-' + self.name)\n",
    "        logging.debug('m3u filename set to: %s', self.m3u)\n",
    "        \n",
    "        # recurse the JSON object and find all the audioData information\n",
    "        for key, val in enumerate(self.jsonData['audioData']):\n",
    "            logging.debug('%s - %s', int(key)+1, val['title'] )\n",
    "            try:\n",
    "                audioURL = val['audioUrl'] \n",
    "                title = val['title']\n",
    "            except Exception as e:\n",
    "                    logging.warning('failed to parse JSON data: %s', e)\n",
    "                    \n",
    "            number = int(key)+1 # set the human readable segment number\n",
    "            filename = re.search(search_FileName, val['audioUrl'].split('/')[-1:][0]).group(1) # set the filename\n",
    "            \n",
    "            # append the segment number\n",
    "            filename = str(number).zfill(3) + '_' + filename\n",
    "            \n",
    "            if filename < 1:\n",
    "                logging.warning('no filename found; dropping segment')\n",
    "                continue\n",
    "\n",
    "            self.addSegment(Segment(audioURL = audioURL, filename = filename, \n",
    "                                    number = number, programName = self.name,\n",
    "                                    title = title))\n",
    "            \n",
    "        return(True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Segment():\n",
    "    '''One segment of a podcast'''\n",
    "    \n",
    "    def __init__(self, audioURL, filename, number, programName, title = None):\n",
    "        '''\n",
    "        Args:\n",
    "            audioURL (str): URL to specific downloadable content\n",
    "            filename (str): output filename\n",
    "            title (str): human readable segment title\n",
    "            programName (str): program Name\n",
    "            number (int): ordinal number of segment\n",
    "            downloaded (boo): true if segment was successfully downloaded\n",
    "            \n",
    "        '''\n",
    "        self.audioURL = audioURL\n",
    "        self.number = number\n",
    "        self.filename = filename\n",
    "        self.title = title\n",
    "        self.programName = programName\n",
    "        self.downloaded = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class showConfig():\n",
    "    '''Configuration object for a downloadable show'''\n",
    "   \n",
    "    def __init__(self, optionsDict = {}):\n",
    "        '''\n",
    "        Args:\n",
    "            optionsDict (dict): dictionary of options to be used in configuration\n",
    "                showname (str): human readable string\n",
    "                fetchmethod (str): method for downloading show (NPR_HTML or NRP_API)\n",
    "                programs (int): number of programs to keep\n",
    "                updatedays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "                updatetime (str): time in 24H HH:MM format after which an update should be attempted\n",
    "                timezone (str): timezone in which to preform time calculatinos\n",
    "                url (str): url to NPR program page\n",
    "        Attributes:\n",
    "            options (dict): dictionary of options\n",
    "            showName (str): human readable name of show\n",
    "            fetchMethod (str): method for downloading show (NPR_HTML or NPR_API)\n",
    "            programs (int): number of programs to keep\n",
    "            updateDays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "            updateTime (str): time in HH:MM after which an update should be attempted\n",
    "            timezone (str): timezone in which to preform time calculations\n",
    "            url (str): url to NPR program page\n",
    "    \n",
    "        '''\n",
    "        \n",
    "        self.options = optionsDict\n",
    "        self.showName = 'No Name'\n",
    "        self.fetchMethod = 'NPR_HTML'\n",
    "        self.programs = 1\n",
    "        self.updateDays = []\n",
    "        self.updateTime = ''\n",
    "        self.timezone = 'EST'\n",
    "        self.url = None\n",
    "        \n",
    "    def verifyConfig(self):\n",
    "        '''\n",
    "        \n",
    "        Validates and sets configuration paramaters for a downloadable show:\n",
    "        \n",
    "        Attributes:\n",
    "            showName (str): human readable name of show\n",
    "            fetchMethod (str): method for downloading show (NPR_HTML or NPR_API)\n",
    "            programs (int): number of programs to keep\n",
    "            updateDays (list): integers [0-6] representing days of the week to update (sun-sat)\n",
    "            updateTime (str): time in HH:MM after which an update should be attempted\n",
    "            timezone (str): timezone in which to preform time calculations\n",
    "            \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns: \n",
    "            bool: True - configuration is OK or has been made OK\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        logging.debug('verifying configuration')\n",
    "        \n",
    "        if 'showname' in self.options:\n",
    "            self.showName = self.options['showname']\n",
    "            logging.debug('show name set to: %s', self.showName)\n",
    "        else: \n",
    "            logging.warn('no show name found; set to: %s', self.showName)\n",
    "        \n",
    "        if 'programs' in self.options:\n",
    "            try:\n",
    "                self.programs = int(self.options['programs'])\n",
    "            except ValueError as e:\n",
    "                logging.error('programs option not an integer: %s', e)\n",
    "                logging.error('programs set to: %s', self.programs)\n",
    "        else:\n",
    "            logging.warning('no programs setting found in configuration file for %s; set to: %s', self.showName, self.programs)\n",
    "        \n",
    "        \n",
    "        if 'url' in self.options:\n",
    "            if re.match('^http:\\/\\/.*', self.options['url'].lower()):\n",
    "                self.url = self.options['url']\n",
    "            else:\n",
    "                logging.error('no vlaid URL found for %s: %s', self.showName, self.options['url'])\n",
    "                return(False)\n",
    "        else:\n",
    "            logging.error('no valid URL found for %s', self.showName)\n",
    "            logging.error('valid url format: http://host.com/show/')\n",
    "            return(False)\n",
    "        \n",
    "        \n",
    "        if 'fetchmethod' in self.options:\n",
    "            self.fetchMethod = self.options['fetchmethod']\n",
    "            logging.debug('fetchmethod set to: %s', self.fetchMethod)\n",
    "        else:\n",
    "            logging.warning('no fetchmethod set; setting to: %s', self.fetchMethod)\n",
    "        \n",
    "        # This all may be undeeded; consider removing all of this.\n",
    "        # user cmd+/ to uncomment the block below        \n",
    "#         defaultUpdateDays = [1, 2, 3, 4, 5, 6, 7]\n",
    "#         if 'updatedays' in self.options:\n",
    "#             # remove any non-numerals, -, or commas\n",
    "#             self.options['updatedays'] = re.sub('[^\\,0-9]+', '', self.options['updatedays'])\n",
    "#             # clear out any superflous commas\n",
    "#             self.options['updatedays'] = re.sub('\\,\\,', ',', self.options['updatedays']) \n",
    "            \n",
    "#             try:\n",
    "#                 self.updateDays = map(int, self.options['updatedays'].split(','))\n",
    "#             except ValueError as e:\n",
    "#                 logging.warn('bad or missing update date format: %s',e )\n",
    "#                 logging.warn('using sun through sat')\n",
    "#                 self.updateDays = defaultUpdateDays\n",
    " \n",
    "#             badValues = []\n",
    "#             for index in self.updateDays:\n",
    "#                 # check for bad values that are less than 1 or greater than 7\n",
    "#                 if index > 7 or index < 1:\n",
    "#                     logging.warn('found invalid day in configuration file: %s',index)\n",
    "#                     badValues.append(index)   \n",
    "                    \n",
    "#             # get rid of bad values\n",
    "#             for index in badValues:\n",
    "#                 logging.warn('removing invalid day: %s', index)\n",
    "#                 self.updateDays.remove(index)\n",
    "#             # sort the list \n",
    "#             self.updateDays.sort()\n",
    "#         else:\n",
    "#             # supply a list if none is supplied\n",
    "#             logging.warn('no update days were supplied using sun through sat')\n",
    "#             self.updateDays = defaultUpdateDays\n",
    "        \n",
    "        \n",
    "#         # do some validation of valid timezones\n",
    "#         if 'timezone' in self.options:\n",
    "#             if self.options['timezone'].upper() in pytz.all_timezones:\n",
    "#                 self.timezone = self.options['timezone'].upper()\n",
    "#             else: \n",
    "#                 logging.error('specified timezone not found in database: %s', self.options['timezone'])\n",
    "#                 logging.error('setting timezone to: UTC')\n",
    "#                 self.timezone = 'UTC'\n",
    "                \n",
    "#         else:\n",
    "#             logging.warning('no timezone found; setting timezone to: %s', self.timezone)\n",
    "\n",
    "    \n",
    "        \n",
    "        # do some validation of valid times\n",
    "        # time format\n",
    "        timeFMT = '%H:%M'\n",
    "        defaultTime = '23:59'\n",
    "        if 'updatetime' in self.options:\n",
    "            # sanitize the time string datetime.time(datetime.strptime('13:55', timeFMT))\n",
    "            try:\n",
    "                self.updateTime = datetime.time(datetime.strptime(re.sub('[^0-9\\:]+', '', self.options['updatetime']), timeFMT))\n",
    "            except ValueError as e:\n",
    "                logging.error('bad updatetime time format: %s', self.options['updatetime'])\n",
    "                logging.error('setting updatetime to: %s', defaultTime)\n",
    "                self.updateTime = datetime.time(datetime.strptime(defaultTime, timeFMT))    \n",
    "        else:\n",
    "            self.updateTime = datetime.time(datetime.strptime(defaultTime, timeFMT))\n",
    "            \n",
    "        \n",
    "        return(True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    \n",
    "    #### init variables \n",
    "    # list of show configurations found in configuration file\n",
    "    showsConfig = []\n",
    "    \n",
    "    # list of program episodes to download\n",
    "    episodes = []\n",
    "    \n",
    "    ##### Default values for basic command line configuration settings\n",
    "    # default configuration file\n",
    "    cfgFile = './settings.ini' # this may be unneded as it set in the commandline parser by default\n",
    "    ##### Default values for basic configuration settings\n",
    "    \n",
    "    \n",
    "    # disable -h for help so the second parser can deal with this\n",
    "    # http://stackoverflow.com/questions/3609852/which-is-the-best-way-to-allow-configuration-options-be-overridden-at-the-comman\n",
    "    cmdlineParser = argparse.ArgumentParser(description = __doc__, \n",
    "                                           formatter_class = argparse.RawDescriptionHelpFormatter,\n",
    "                                          add_help = False)\n",
    "    # handle the jupyter -f option while developing in jupyter ipython notebook\n",
    "    #cmdlineParser.add_argument('-f', '--fconfig', help='fake config file', action='store')\n",
    "    # set the configuration file\n",
    "    cmdlineParser.add_argument('-c', '--configfile', help='configuration file', metavar='FILE',\n",
    "                              action='store', default = cfgFile)\n",
    "    # determine if this is a dry run or not\n",
    "    cmdlineParser.add_argument('-d', '--dryrun', help='preform a dry-run with no downloads',\n",
    "                              action='store_true', default=False)\n",
    "    cmdlineParser.add_argument('-L', '--logfile', help = 'enable logging to file', \n",
    "                               action = 'store_true', default = False)\n",
    "    cmdlineParser.add_argument('-o', '--outputpath', action = 'store', metavar = 'PATH', \n",
    "                        help = 'path to output downloaded files')\n",
    "    cmdlineParser.add_argument('-t', '--timeout', action = 'store')\n",
    "    cmdlineParser.add_argument('-v', '--verbose', action = 'count', \n",
    "                        help = 'verbose mode; add more -v to increase verbosity')\n",
    "    #parser.add_argument('-f', '--fake', default = None, help = 'fake option to deal with bug between jupyter and argparse; ignore this')\n",
    "    \n",
    "    \n",
    "    # reamining arguments stored in unknownArgs\n",
    "    args, unknownArgs = cmdlineParser.parse_known_args()\n",
    "    \n",
    "\n",
    "    \n",
    "    # useful for testing with jupyter/ipython when running this function over and over\n",
    "    # removes handlers that should only be added once\n",
    "    log = logging.getLogger()\n",
    "    if len(log.handlers) > 0:\n",
    "        for each in range(0, len(log.handlers)):\n",
    "            log.removeHandler(log.handlers[0])\n",
    "    \n",
    "    # set the log format:\n",
    "    # [  DEBUG 2017-02-12 19:14] loading module: requests\n",
    "    logFormatter = logging.Formatter('[%(levelname)8s %(asctime)s] %(message)s', '%Y-%m-%d %H:%M')\n",
    "    consoleFormatter = logging.Formatter('[%(levelname)-8s] %(message)s')\n",
    "    # set root logger\n",
    "    rootLogger = logging.getLogger()\n",
    "       \n",
    "    # set the default logging level\n",
    "    if args.verbose:\n",
    "        logLevel = logging.WARN - args.verbose * 10\n",
    "        if (50 < logLevel) or (logLevel < 10):\n",
    "            logLevel = 10\n",
    "        rootLogger.setLevel(logLevel)\n",
    "    else:\n",
    "        rootLogger.setLevel(logging.WARN)\n",
    "        \n",
    "    # add a conshole handle to the root logger\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler) \n",
    "    \n",
    "    logging.info('%s started log %s', div(20, '#'), div(20, '#'))   \n",
    "    \n",
    "    # load non-standard python libraries\n",
    "    loadModules()\n",
    "    \n",
    "    # set the configuration parser\n",
    "    configParser = ConfigParser.SafeConfigParser()\n",
    "    # open and read configuration file set at the command line \n",
    "    configParser.read(args.configfile)\n",
    "    if 'Default' not in configParser.sections():\n",
    "        logging.fatal('No \"Default\" section in configurationf file %s', args.configfile)\n",
    "        sys.exit(2)\n",
    "        \n",
    "    # required options in 'Default' section in \n",
    "    # dict {'option name' : [configParser.get(float, boolean), 'default value]}\n",
    "    required = {'outputpath' : [configParser.get, './DownloadedShows']}\n",
    "    \n",
    "    optional = {'dryrun' : [configParser.getboolean, False],\n",
    "                'timeout' : [configParser.getfloat, 5], \n",
    "                'loglevel': [configParser.get, 'WARNING'],\n",
    "                'logfile' : [configParser.getboolean, False],\n",
    "                'useragent': [configParser.get, \"\"]}\n",
    "    # look for each required option and set to default if not found\n",
    "    default = {}\n",
    "    for key in required:\n",
    "        try:\n",
    "            default[key] = required[key][0]('Default', key)\n",
    "        except (ConfigParser.NoSectionError, ConfigParser.NoOptionError) as e:\n",
    "            logging.error('error in configuraiton file: %s', e)\n",
    "            logging.error('using default value: %s = %s', key, required[key][1])\n",
    "            default[key] = required[key][1]     \n",
    "    \n",
    "    # search for each opitonal option and set to default if not found\n",
    "    for key in optional:\n",
    "        try:\n",
    "            default[key] = optional[key][0]('Default', key)\n",
    "        except ConfigParser.NoOptionError as e:\n",
    "            logging.debug('%s optional setting not found in configuration file', key)\n",
    "            logging.debug('this is OK!')\n",
    "            logging.debug('setting to default: %s', optional[key][1])\n",
    "            default[key] = optional[key][1]\n",
    "    \n",
    "    # merge the command line with the config file options\n",
    "    parser = argparse.ArgumentParser(parents=[cmdlineParser])\n",
    "    parser.set_defaults(**default)\n",
    "    \n",
    "    # add all the known arguments to the parserArgs namespace, discard any unknown arguments\n",
    "    parserArgs, uknownArgs = parser.parse_known_args()\n",
    " \n",
    "    # add a file handler if it is specified in the configuration file or command line\n",
    "    if parserArgs.logfile:\n",
    "        # Add the a file handle to the root logger\n",
    "        fileHandler = logging.FileHandler(programName+'.log')\n",
    "        fileHandler.setFormatter(logFormatter)\n",
    "        rootLogger.addHandler(fileHandler)\n",
    "\n",
    "    # match the log level set in the config file or on the command line\n",
    "    if parserArgs.loglevel and not args.verbose:\n",
    "        if isinstance(logging.getLevelName(parserArgs.loglevel.upper()), int):\n",
    "            rootLogger.setLevel(parserArgs.loglevel.upper())\n",
    "\n",
    "    if len(unknownArgs) > 0:\n",
    "        logging.warn('ignoring unknown command line options:')\n",
    "        for arg in unknownArgs:\n",
    "            logging.warn('     %s', arg)\n",
    "        \n",
    "    # verify and use parserArgs below:\n",
    "    if parserArgs.timeout > 120:\n",
    "        logging.warn('timeout values under 120s are reccomended: %s', parserArgs.timeout)    \n",
    "    \n",
    "    # add a trailing '/' to the output path\n",
    "    if not re.match('.*\\/$', parserArgs.outputpath):\n",
    "        parserArgs.outputpath = str(parserArgs.outputpath) + str('/')        \n",
    "    \n",
    "    # search for all the show sections in the configuration file \n",
    "    \n",
    "    # this for loop is a mess; I need to deal with this in a sane way without the continue\n",
    "    sectionIndex = 0\n",
    "    logging.debug('%s searching config file for shows', div(10))\n",
    "    for section in configParser.sections():\n",
    "        # find all show descriptiors\n",
    "        if '%' in section and '#' not in section:\n",
    "            logging.info('found show: %s', section)\n",
    "            showsConfig.append(showConfig((dict(configParser.items(section)))))\n",
    "            if showsConfig[sectionIndex].verifyConfig():\n",
    "                # if no name is set, use the show descriptor \n",
    "                if not 'showname' in showsConfig[sectionIndex].options:\n",
    "                    showsConfig[sectionIndex].showName = str(section).replace('%', '')\n",
    "                    logging.warning('No show name found in configuration file\\nusing section name: %s', showsConfig[sectionIndex].showName)\n",
    "            else:\n",
    "                logging.error('unable to verify configuration for %s; discarding', showsConfig[sectionIndex].showName)\n",
    "                # remove the most last list item\n",
    "                showsConfig.pop()\n",
    "                # move on to the next element\n",
    "                continue\n",
    "            sectionIndex += 1\n",
    "\n",
    "    # exit if no shows were found        \n",
    "    if len(showsConfig) == 0:\n",
    "        logging.critical('no shows found in configuration file: %s', args.configfile)\n",
    "        exit(1)\n",
    "    \n",
    "    # parse each show section in the configuration file, validate and add it to the list for downloading\n",
    "    logging.debug('%s checking for shows to download', div(10))\n",
    "    for each in showsConfig:\n",
    "        # create a time object (H:M:S)\n",
    "        nowTime = datetime.time(datetime.now(pytz.timezone(each.timezone)))\n",
    "        # create a date object\n",
    "        nowDate = datetime.date(datetime.now(pytz.timezone(each.timezone)))\n",
    "        \n",
    "        # create an NPREpisode object and populate\n",
    "        logging.debug('%s parsing configuration for [%s]', div(5), each.showName)\n",
    "        myEpisode = NPREpisode(name = each.showName, outputBasePath = parserArgs.outputpath)\n",
    "        #myEpisode.outputBasePath = parserArgs.outputpath\n",
    "        myEpisode.programURL = each.url\n",
    "        \n",
    "\n",
    "        \n",
    "        # this may not be neccesary; can check for show any day.\n",
    "        # check the day of the week; if it's not in range, skip this show\n",
    "        #if nowDate.isoweekday() not in each.updateDays:\n",
    "        #    logging.debug('update days in set timezone for this show (%s) does not include today: %s', each.updateDays, nowDate.isoweekday())\n",
    "        #    logging.info('skipping episode for show: %s (wrong day)', each.showName)\n",
    "        #    # skip the rest of this loop\n",
    "        #    continue\n",
    "        \n",
    "        # only the HTML method is currently implemented\n",
    "        if myEpisode.getepisode_HTML():\n",
    "            episodes.append(myEpisode)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        # this may not be neccesary; only new shows are downloaded; past shows are totally ignored\n",
    "        # check the time; if it's too early, skip the show\n",
    "        #if (nowTime > each.updateTime):\n",
    "        #    logging.debug('the current time in set timezone for this show (%s) is currently later than set update time: %s', each.timezone, each.updateTime)\n",
    "        #    logging.info('fetching episode information for show: %s', each.showName)\n",
    "        # add the episode to the download list if the html fetch was successful\n",
    "        if myEpisode.getepisode_HTML():\n",
    "            episodes.append(myEpisode)\n",
    "        #else: \n",
    "        #    logging.debug('the current time in set timezone for this show (%s) is earlier than set update time: %s', each.timezone, each.updateTime)\n",
    "        #    logging.info('skipping episode for show: %s (too early)', each.showName)\n",
    "            \n",
    "    logging.info('%s downloading episodes', div(5))\n",
    "    logging.debug('found %s episodes', len(episodes))\n",
    "    randomGenerator = SystemRandom()\n",
    "    for index, eachEp in enumerate(episodes):\n",
    "        if eachEp.download(parserArgs.dryrun, timeout = parserArgs.timeout, \n",
    "                           useragent = randomGenerator.choice(parserArgs.useragent.split('|'))):\n",
    "            # write m3u if there was a successful download\n",
    "            eachEp.writeM3U()\n",
    "            # tag segments if there was a successful download \n",
    "            #if not parserArgs.dryrun:\n",
    "            eachEp.tagSegments()\n",
    "        # this is a bit of a mess: this needs to be added to the episode at some point if it's going to used\n",
    "        logging.debug('%s cleaning show: %s', div(5), showsConfig[index].showName)\n",
    "        logging.debug('keeping a maximum of %s episodes', showsConfig[index].programs)\n",
    "        eachEp.cleanUp(keep = showsConfig[index].programs, dryrun = parserArgs.dryrun)\n",
    "    \n",
    "    print 'done'\n",
    "    return(parserArgs)\n",
    "        \n",
    "    \n",
    "        \n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mainNew(argv=None):\n",
    "    ############### init variables \n",
    "    \n",
    "    ##### LOGGING INIT\n",
    "    # init the log; this removes any old log handlers (this is particularly useful when testing in an IDE)\n",
    "    log = logging.getLogger()\n",
    "    if len(log.handlers) > 0:\n",
    "        for each in range(0, len(log.handlers)):\n",
    "            log.removeHandler(log.handlers[0])\n",
    "            \n",
    "    # set the log format:\n",
    "    # [  DEBUG 2017-02-12 19:14] loading module: requests\n",
    "    logFormatter = logging.Formatter('[%(levelname)8s %(asctime)s] %(message)s', '%Y-%m-%d %H:%M')\n",
    "    consoleFormatter = logging.Formatter('[%(levelname)-8s] %(message)s')\n",
    "    # set root logger\n",
    "    rootLogger = logging.getLogger()       \n",
    "    \n",
    "    # add a conshole handle to the root logger\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler) \n",
    "    \n",
    "    ############### CONFIGURATION VARIABLES\n",
    "    # default configuration file\n",
    "    cfgFile = 'podcastdownload.ini' # this may be unneded as it set in the commandline parser by default\n",
    "    \n",
    "    # set the configuration parser\n",
    "    configParser = ConfigParser.SafeConfigParser()\n",
    "\n",
    "    # required options in 'Main' section in \n",
    "    # dict {'option name' : [configParser.getfloat; get; getboolean, 'default value]}   \n",
    "    mainSection = 'Main'    \n",
    "    # list any special reserved section names here\n",
    "    reservedSectionNames = [mainSection]\n",
    "    required = {'outputpath' : [configParser.get, './DownloadedShows']}\n",
    "    \n",
    "    optional = {'dryrun' : [configParser.getboolean, False],\n",
    "                'timeout' : [configParser.getfloat, 5], \n",
    "                'loglevel': [configParser.get, 'WARNING'],\n",
    "                'logfile' : [configParser.getboolean, False],\n",
    "                'useragent': [configParser.get, '']}\n",
    "    \n",
    "    ############### SHOW/DOWNLOAD VARIABLES\n",
    "    # list of show configurations found in configuration file\n",
    "    shows = []\n",
    "    \n",
    "    # list of program episodes to download\n",
    "    downloadEpisodes = []\n",
    "    \n",
    "    # random generator object\n",
    "    randomGenerator = SystemRandom()\n",
    "    \n",
    "\n",
    "    ############### READ AND ACT ON COMMAND LINE ARGUMENTS  \n",
    "    # disable -h for help so the second parser can deal with this\n",
    "    # http://stackoverflow.com/questions/3609852/which-is-the-best-way-to-allow-configuration-options-be-overridden-at-the-comman\n",
    "    cmdlineParser = argparse.ArgumentParser(description = __doc__, \n",
    "                                           formatter_class = argparse.RawDescriptionHelpFormatter,\n",
    "                                          add_help = False)\n",
    "    # handle the jupyter -f option while developing in jupyter ipython notebook\n",
    "    #cmdlineParser.add_argument('-f', '--fconfig', help='fake config file', action='store')\n",
    "    # set the configuration file\n",
    "    cmdlineParser.add_argument('-c', '--configfile', help='configuration file', metavar='FILE',\n",
    "                              action='store', default = cfgFile)\n",
    "    # determine if this is a dry run or not\n",
    "    cmdlineParser.add_argument('-d', '--dryrun', help='preform a dry-run with no downloads',\n",
    "                              action='store_true', default=False)\n",
    "    cmdlineParser.add_argument('-L', '--logfile', help = 'enable logging to file', \n",
    "                               action = 'store_true', default = False)\n",
    "    cmdlineParser.add_argument('-o', '--outputpath', action = 'store', metavar = 'PATH', \n",
    "                        help = 'path to output downloaded files')\n",
    "    cmdlineParser.add_argument('-t', '--timeout', action = 'store')\n",
    "    cmdlineParser.add_argument('-v', '--verbose', action = 'count', \n",
    "                        help = 'verbose mode; add more -v to increase verbosity')\n",
    "  \n",
    "    # reamining arguments stored in unknownArgs\n",
    "    args, unknownArgs = cmdlineParser.parse_known_args()\n",
    "    \n",
    "    # set the logging level based on command line options\n",
    "    if args.verbose:\n",
    "        # remove 10 for each V bringing the level from 40 (ERROR) down\n",
    "        logLevel = logging.ERROR - args.verbose * 10\n",
    "        # if the log level shold somehow end up above 50 or below 10 it is set to 10 (DEBUG)\n",
    "        if (50 < logLevel) or (logLevel < 10):\n",
    "            logLevel = logging.DEBUG\n",
    "        rootLogger.setLevel(logLevel)\n",
    "    else:\n",
    "        # the default level is ERROR \n",
    "        rootLogger.setLevel(logging.ERROR)    \n",
    "        \n",
    "    rootLogger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    ############### READ AND ACT ON CONFIGURATION FILE\n",
    "    configParser.read(cfgFile)\n",
    "    \n",
    "    if mainSection not in configParser.sections():\n",
    "        logging.error('No \"%s\" section in configuration file %s', mainSection, args.configfile)\n",
    "        logging.error('exiting')\n",
    "        sys.exit()\n",
    "    \n",
    "    # look for each required option and set to default specified above if not found\n",
    "    # container for all default settings read from config file\n",
    "    default = {}\n",
    "    \n",
    "    for key in required:\n",
    "        try:\n",
    "            #default[key] = configParser.get(mainSection, key)\n",
    "            default[key] = required[key][0](mainSection, key)\n",
    "        except (ConfigParser.NoSectionError, ConfigParser.NoOptionError) as e:\n",
    "            logging.error('problem in configuraiton file: %s', e)\n",
    "            logging.error('using default value: %s = %s', key, required[key][1])\n",
    "            default[key] = required[key][1]     \n",
    "    \n",
    "    for key in optional:\n",
    "        try:\n",
    "            default[key] = optional[key][0](mainSection, key)\n",
    "        except (ConfigParser.NoSectionError, ConfigParser.NoOptionError) as e:\n",
    "            logging.info('\"%s\" optional setting not found in configuration file \"%s\" section', key, 'Default')\n",
    "            logging.info('this is OK!')\n",
    "            logging.info('using default value: %s', optional[key][1])\n",
    "            default[key] = optional[key][1]\n",
    "            \n",
    " \n",
    "\n",
    "    ############### MERGE COMMANDLINE AND CONFIGURATION FILES TOGETHER\n",
    "    # add in commandline arguments\n",
    "    parser = argparse.ArgumentParser(parents=[cmdlineParser])\n",
    "    # add in configuration file defaults\n",
    "    parser.set_defaults(**default)\n",
    "    \n",
    "    # add all the known arguments to the parserArgs namespace, discard any unknown arguments\n",
    "    parserArgs, uknownArgs = parser.parse_known_args()\n",
    " \n",
    "    # add a file handler for the file log if needed\n",
    "    if parserArgs.logfile:\n",
    "        # Add the a file handle to the root logger\n",
    "        fileHandler = logging.FileHandler(programName+'.log')\n",
    "        fileHandler.setFormatter(logFormatter)\n",
    "        rootLogger.addHandler(fileHandler)\n",
    "\n",
    "    # match the loging level set in the config file or on the command line\n",
    "    # commandline -v options override\n",
    "    if parserArgs.loglevel and not args.verbose:\n",
    "        if isinstance(logging.getLevelName(parserArgs.loglevel.upper()), int):\n",
    "            rootLogger.setLevel(parserArgs.loglevel.upper())\n",
    "\n",
    "    # verify configuration options before proceeding\n",
    "    # deal with unknwon options\n",
    "    if len(unknownArgs) > 0:\n",
    "        logging.warn('ignoring unknown command line options:')\n",
    "        for arg in unknownArgs:\n",
    "            logging.warn('     %s', arg)\n",
    "        \n",
    "    # check for unreasonable timeouts\n",
    "    if parserArgs.timeout > 120:\n",
    "        logging.warn('timeout values under 120s are reccomended: %s', parserArgs.timeout)    \n",
    "    \n",
    "    # add a trailing '/' to the output path\n",
    "    if not re.match('.*\\/$', parserArgs.outputpath):\n",
    "        parserArgs.outputpath = str(parserArgs.outputpath) + str('/')        \n",
    "\n",
    "        \n",
    "    ############### LOAD NON STANDARD MODULES\n",
    "    loadModules()\n",
    "        \n",
    "    ############### READ SHOW SEGMENTS FROM CONFIGURATION FILE\n",
    "    logging.info('%s searching config file for shows', div(10, '-'))\n",
    "        \n",
    "    for section in configParser.sections():\n",
    "        if section not in reservedSectionNames and '#' not in section:\n",
    "            logging.info('%s found show: %s', div(5), section)\n",
    "            show = (showConfig((dict(configParser.items(section)))))\n",
    "            if show.verifyConfig():\n",
    "                shows.append(show)\n",
    "            else:\n",
    "                logging.error('bad configuration for show \"%s\", skipping', section)\n",
    "    if len(shows) <= 0:\n",
    "        logging.critical('no shows found in configuration file') \n",
    "        logging.critical('nothing to do')\n",
    "        sys.exit()\n",
    "    \n",
    "    ############### PARSE CONIFIGURATION FOR EACH SHOW\n",
    "    logging.info('%s parsing show information', div(10, '-'))\n",
    "    for show in shows:\n",
    "        # create an NPREpisode object and populate\n",
    "        logging.debug('%s parsing configuration for show: [%s]', div(5), show.showName)\n",
    "        myEpisode = NPREpisode(name = show.showName, outputBasePath = parserArgs.outputpath, keep = show.programs)\n",
    "        #myEpisode.outputBasePath = parserArgs.outputpath\n",
    "        myEpisode.programURL = show.url\n",
    "        if myEpisode.getepisode_HTML():\n",
    "            downloadEpisodes.append(myEpisode)\n",
    "        else:\n",
    "            logging.error('error fetching show JSON information; see errors above')\n",
    "    \n",
    "    ############### DOWNLOAD EACH SHOW\n",
    "    logging.info('%s downloading episodes', div(10, '-'))\n",
    "    logging.debug('found %s episodes', len(downloadEpisodes))\n",
    "    for episode in downloadEpisodes:\n",
    "        logging.info('%s downloading: %s', div(5), episode.name)\n",
    "        #if eachEp.download(parserArgs.dryrun, timeout = parserArgs.timeout, \n",
    "                          # useragent = randomGenerator.choice(parserArgs.useragent.split('|'))):\n",
    "        if episode.download(dryrun = parserArgs.dryrun, timeout = parserArgs.timeout):\n",
    "                        #useragent = randomGenerator.choice(parserArgs.useragent.split('|'))):\n",
    "            if not parserArgs.dryrun:\n",
    "                episode.writeM3U()\n",
    "                episode.tagSegments()\n",
    "            logging.info('success!')\n",
    "            logging.info('%s cleaning up old episodes fpr %s', div(5), episode.name)\n",
    "            #logging.debug('keeping a maximum of %s episodes', episode.keep)\n",
    "            removed = episode.cleanUp()\n",
    "            logging.debug('removed: %s', removed)\n",
    "\n",
    "    \n",
    "    return(shows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '-f', '/home/txoof/.local/share/jupyter/runtime/kernel-e8dfc9c7-1cfb-4bdd-9af3-d334263ffba1.json']\n",
      "[    INFO 2017-02-20 21:33] \"useragent\" optional setting not found in configuration file \"Default\" section\n",
      "[    INFO 2017-02-20 21:33] this is OK!\n",
      "[    INFO 2017-02-20 21:33] using default value: \n",
      "[ WARNING 2017-02-20 21:33] ignoring unknown command line options:\n",
      "[ WARNING 2017-02-20 21:33]      -f\n",
      "[ WARNING 2017-02-20 21:33]      /home/txoof/.local/share/jupyter/runtime/kernel-e8dfc9c7-1cfb-4bdd-9af3-d334263ffba1.json\n",
      "[   DEBUG 2017-02-20 21:33] loading module: requests\n",
      "[   DEBUG 2017-02-20 21:33] loading module: mutagen.mp3\n",
      "[   DEBUG 2017-02-20 21:33] loading module: mutagen.mp4\n",
      "[    INFO 2017-02-20 21:33] ---------- searching config file for shows\n",
      "[    INFO 2017-02-20 21:33] ***** found show: All Things Considered\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:33] show name set to: All Things Considered\n",
      "[   DEBUG 2017-02-20 21:33] fetchmethod set to: NPR_HTML\n",
      "[    INFO 2017-02-20 21:33] ***** found show: Morning Edition\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:33] show name set to: Morning Edition\n",
      "[   DEBUG 2017-02-20 21:33] fetchmethod set to: NPR_HTML\n",
      "[    INFO 2017-02-20 21:33] ***** found show: Weekend Edition Saturday\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:33] show name set to: Weekend Edition Saturday\n",
      "[   DEBUG 2017-02-20 21:33] fetchmethod set to: NPR_HTML\n",
      "[    INFO 2017-02-20 21:33] ***** found show: Weekend Edition Sunday\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:33] show name set to: Weekend Edition Sunday\n",
      "[   DEBUG 2017-02-20 21:33] fetchmethod set to: NPR_HTML\n",
      "[    INFO 2017-02-20 21:33] ***** found show: Wait Wait Don't Tell Me\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:33] show name set to: Wait Wait Don't Tell Me\n",
      "[   DEBUG 2017-02-20 21:33] fetchmethod set to: NPR_HTML\n",
      "[    INFO 2017-02-20 21:33] ***** found show: Bogus\n",
      "[   DEBUG 2017-02-20 21:33] verifying configuration\n",
      "[ WARNING 2017-02-20 21:33] no show name found; set to: No Name\n",
      "[   ERROR 2017-02-20 21:33] no vlaid URL found for No Name: foo.com\n",
      "[   ERROR 2017-02-20 21:33] bad configuration for show \"Bogus\", skipping\n",
      "[    INFO 2017-02-20 21:33] ---------- parsing show information\n",
      "[   DEBUG 2017-02-20 21:33] ***** parsing configuration for show: [All Things Considered]\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: All-Things-Considered\n",
      "[   DEBUG 2017-02-20 21:33] fetching episode info via HTML method\n",
      "[   DEBUG 2017-02-20 21:33] source: http://www.npr.org/programs/all-things-considered/\n",
      "[   DEBUG 2017-02-20 21:33] HTML retrieved successfully\n",
      "[   DEBUG 2017-02-20 21:33] show date: 2017-02-19\n",
      "[   DEBUG 2017-02-20 21:33] JSON program information found for ALL THINGS CONSIDERED\n",
      "[   DEBUG 2017-02-20 21:33] setting name to: All Things Considered\n",
      "[   DEBUG 2017-02-20 21:33] segments found: 10\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: 2017-02-19_ATCO\n",
      "[   DEBUG 2017-02-20 21:33] output path set to: ./output/All-Things-Considered/2017-02-19_ATCO/\n",
      "[   DEBUG 2017-02-20 21:33] m3u filename set to: 2017-02-19-ALL-THINGS-CONSIDERED.m3u\n",
      "[   DEBUG 2017-02-20 21:33] 1 - America's European Allies Still Seeing Mixed Messages From Trump Administration\n",
      "[   DEBUG 2017-02-20 21:33] 2 - Trump Says, 'Look What's Happening In Sweden.' Sweden Asks, 'Wait, What?'\n",
      "[   DEBUG 2017-02-20 21:33] 3 - On Edge After Immigration Raids, Families Make Plans For If They Get Split Up\n",
      "[   DEBUG 2017-02-20 21:33] 4 - NBA Players More Confident To Speak Out On Political Issues Than Other Sport Leagues\n",
      "[   DEBUG 2017-02-20 21:33] 5 - In 'Chapter & Verse,' African American Man Tries To Return to Daily Life After Prison\n",
      "[   DEBUG 2017-02-20 21:33] 6 - Lack Of Education Leads To Lost Dreams And Low Income For Many Jehovah's Witnesses\n",
      "[   DEBUG 2017-02-20 21:33] 7 - Hampton University President Says 'The Quad' Doesn't Correctly Represent HBCUs\n",
      "[   DEBUG 2017-02-20 21:33] 8 - Seminole Patchwork: Admiration And Appropriation\n",
      "[   DEBUG 2017-02-20 21:33] 9 - 'The Good Fight' Offers Edgier Version of 'The Good Wife' In Series Debut\n",
      "[   DEBUG 2017-02-20 21:33] 10 - In 'Get Out,' Jordan Peele Tackles The 'Human Horror' Of Racial Fear\n",
      "[   DEBUG 2017-02-20 21:33] ***** parsing configuration for show: [Morning Edition]\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: Morning-Edition\n",
      "[   DEBUG 2017-02-20 21:33] fetching episode info via HTML method\n",
      "[   DEBUG 2017-02-20 21:33] source: http://www.npr.org/programs/morning-edition/\n",
      "[   DEBUG 2017-02-20 21:33] HTML retrieved successfully\n",
      "[   DEBUG 2017-02-20 21:33] show date: 2017-02-20\n",
      "[   DEBUG 2017-02-20 21:33] JSON program information found for MORNING EDITION\n",
      "[   DEBUG 2017-02-20 21:33] setting name to: Morning Edition\n",
      "[   DEBUG 2017-02-20 21:33] segments found: 17\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: 2017-02-20_MED\n",
      "[   DEBUG 2017-02-20 21:33] output path set to: ./output/Morning-Edition/2017-02-20_MED/\n",
      "[   DEBUG 2017-02-20 21:33] m3u filename set to: 2017-02-20-MORNING-EDITION.m3u\n",
      "[   DEBUG 2017-02-20 21:33] 1 - Fight Begins To Wrest Control Of Western Mosul From ISIS\n",
      "[   DEBUG 2017-02-20 21:33] 2 - The Mile High Promise, And Risk, Of School Choice \n",
      "[   DEBUG 2017-02-20 21:33] 3 - Got Back Pain? Try Yoga Or Massage Before Reaching For The Pills\n",
      "[   DEBUG 2017-02-20 21:33] 4 - Can Poetry Keep You Young? Science Is Still Out, But The Heart Says Yes\n",
      "[   DEBUG 2017-02-20 21:33] 5 - Whoops: Michelin Star Goes To Wrong French Restaurant\n",
      "[   DEBUG 2017-02-20 21:33] 6 - Famine Declared In Parts Of War-Torn South Sudan\n",
      "[   DEBUG 2017-02-20 21:33] 7 - Have Spare Time? Try To Discover A Planet\n",
      "[   DEBUG 2017-02-20 21:33] 8 - Mattress No Longer Delegated To Bottom Of Shopping List\n",
      "[   DEBUG 2017-02-20 21:33] 9 - Alison Krauss And Buddy Cannon On The Working Relationship Behind 'Windy City'\n",
      "[   DEBUG 2017-02-20 21:33] 10 - Donald Trump, Mike Pence To Spend Presidents Day Working\n",
      "[   DEBUG 2017-02-20 21:33] 11 - Environmentalists Are At Odds With Kenya's Government Over Rail Line\n",
      "[   DEBUG 2017-02-20 21:33] 12 - Mexico Braces For Flood Of Returnees As Trump Cracks Down On Immigration\n",
      "[   DEBUG 2017-02-20 21:33] 13 - China Monitors Assassination Probe Of North Korean Kim Jong Nam\n",
      "[   DEBUG 2017-02-20 21:33] 14 - Recycling Plant Employee In Ontario Finds Big Bucks Inside TV\n",
      "[   DEBUG 2017-02-20 21:33] 15 - Facebook Wants Great Power, But What About Responsibility? \n",
      "[   DEBUG 2017-02-20 21:33] 16 - Scientists Use Flying Laboratory To Track Greenhouse Gases\n",
      "[   DEBUG 2017-02-20 21:33] 17 - Lead Ammunition Poisons Wildlife But Too Expensive To Change, Hunters Say\n",
      "[   DEBUG 2017-02-20 21:33] ***** parsing configuration for show: [Weekend Edition Saturday]\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: Weekend-Edition-Saturday\n",
      "[   DEBUG 2017-02-20 21:33] fetching episode info via HTML method\n",
      "[   DEBUG 2017-02-20 21:33] source: http://www.npr.org/programs/weekend-edition-saturday/\n",
      "[   DEBUG 2017-02-20 21:33] HTML retrieved successfully\n",
      "[   DEBUG 2017-02-20 21:33] show date: 2017-02-18\n",
      "[   DEBUG 2017-02-20 21:33] JSON program information found for WEEKEND EDITION SATURDAY\n",
      "[   DEBUG 2017-02-20 21:33] setting name to: Weekend Edition Saturday\n",
      "[   DEBUG 2017-02-20 21:33] segments found: 20\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: 2017-02-18_WESA\n",
      "[   DEBUG 2017-02-20 21:33] output path set to: ./output/Weekend-Edition-Saturday/2017-02-18_WESA/\n",
      "[   DEBUG 2017-02-20 21:33] m3u filename set to: 2017-02-18-WEEKEND-EDITION-SATURDAY.m3u\n",
      "[   DEBUG 2017-02-20 21:33] 1 - The State Of U.S.-Russian Relations\n",
      "[   DEBUG 2017-02-20 21:33] 2 - Trump To Step Back Into Familiar Territory With Rally In Florida\n",
      "[   DEBUG 2017-02-20 21:33] 3 - 'Are We Alone?' Churchill Concludes It's Likely Life Circles Other Suns\n",
      "[   DEBUG 2017-02-20 21:33] 4 - Anonymous Leaks Gain New Prominence In Trump-Era Journalism\n",
      "[   DEBUG 2017-02-20 21:33] 5 - A Tale Of Two Kansas Towns: One Thrives As Another Struggles\n",
      "[   DEBUG 2017-02-20 21:33] 6 - Hundreds Of Whales Get Stranded And Die On New Zealand Shore\n",
      "[   DEBUG 2017-02-20 21:33] 7 - When Their Food Ran Out, These Reindeer Kept Digging\n",
      "[   DEBUG 2017-02-20 21:33] 8 - Exhibition Celebrates Merce Cunningham And His Choreography Of Chance\n",
      "[   DEBUG 2017-02-20 21:33] 9 - Squirrel Foils Attempted Theft\n",
      "[   DEBUG 2017-02-20 21:33] 10 - Oddisee's 'The Iceberg' Has A Trove Of Stories Beneath Its Surface\n",
      "[   DEBUG 2017-02-20 21:33] 11 - 'Heed The Protests' Over Obamacare, 'National Review' Editor Says\n",
      "[   DEBUG 2017-02-20 21:33] 12 - Pence And Mattis Commit To NATO, But Ask Europe For More Help\n",
      "[   DEBUG 2017-02-20 21:33] 13 - GOP Leaders Urge Return To 'High-Risk Insurance Pools' That Critics Call Costly\n",
      "[   DEBUG 2017-02-20 21:33] 14 - Massachusetts Hotline Tracks Post-Election Hate\n",
      "[   DEBUG 2017-02-20 21:33] 15 - Life Inches Back To Normal In East Mosul, But Worries Remain\n",
      "[   DEBUG 2017-02-20 21:33] 16 - Saturday Sports: A Winning Streak And A Losing Streak\n",
      "[   DEBUG 2017-02-20 21:33] 17 - Why This High School Band Is Only Buying Music From Composers Of Color\n",
      "[   DEBUG 2017-02-20 21:33] 18 - 'Shining City' Is Packed With Timely Thrills\n",
      "[   DEBUG 2017-02-20 21:33] 19 - 'John Wick 2' Director On 'Hong Kong Approach' To Filmmaking\n",
      "[   DEBUG 2017-02-20 21:33] 20 - Behind 'La La Land,' A Long Relationship Between A Director And A Composer\n",
      "[   DEBUG 2017-02-20 21:33] ***** parsing configuration for show: [Weekend Edition Sunday]\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: Weekend-Edition-Sunday\n",
      "[   DEBUG 2017-02-20 21:33] fetching episode info via HTML method\n",
      "[   DEBUG 2017-02-20 21:33] source: http://www.npr.org/programs/weekend-edition-sunday/\n",
      "[   DEBUG 2017-02-20 21:33] HTML retrieved successfully\n",
      "[   DEBUG 2017-02-20 21:33] show date: 2017-02-19\n",
      "[   DEBUG 2017-02-20 21:33] JSON program information found for WEEKEND EDITION SUNDAY\n",
      "[   DEBUG 2017-02-20 21:33] setting name to: Weekend Edition Sunday\n",
      "[   DEBUG 2017-02-20 21:33] segments found: 20\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: 2017-02-19_WESU\n",
      "[   DEBUG 2017-02-20 21:33] output path set to: ./output/Weekend-Edition-Sunday/2017-02-19_WESU/\n",
      "[   DEBUG 2017-02-20 21:33] m3u filename set to: 2017-02-19-WEEKEND-EDITION-SUNDAY.m3u\n",
      "[   DEBUG 2017-02-20 21:33] 1 - Trump Goes Back To Campaign Mode In Florida\n",
      "[   DEBUG 2017-02-20 21:33] 2 - With Intelligence Leaks, The 'Deep State' Resurfaces\n",
      "[   DEBUG 2017-02-20 21:33] 3 - Omar Abdel-Rahman, Radical Cleric Connected To 1993 World Trade Center Bombing, Dies\n",
      "[   DEBUG 2017-02-20 21:33] 4 - Protests In Paris Over Alleged Rape Of Black Man By Police\n",
      "[   DEBUG 2017-02-20 21:33] 5 - A Thriving Rural Town's Winning Formula Faces New Threats Under Trump Administration\n",
      "[   DEBUG 2017-02-20 21:33] 6 - Government Sues Lance Armstrong, Wants $100 Million\n",
      "[   DEBUG 2017-02-20 21:33] 7 - Space Poop Problem-Solvers Take Home Cash Prizes From NASA\n",
      "[   DEBUG 2017-02-20 21:33] 8 - Sunday Puzzle: Solving This Puzzle Might Mean A Few Outfit Changes\n",
      "[   DEBUG 2017-02-20 21:33] 9 - After 21 Nominations, Will Sound Mixer Kevin O'Connell Finally Win His Oscar?\n",
      "[   DEBUG 2017-02-20 21:33] 10 - Pegi Young's New Album Is Emotionally 'Raw'\n",
      "[   DEBUG 2017-02-20 21:33] 11 - The Call-In: Answering Your Questions About 'Sanctuary Cities'\n",
      "[   DEBUG 2017-02-20 21:33] 12 - How 'Little Tokyo' Of Los Angeles Changed Into 'Bronzeville' And Back Again\n",
      "[   DEBUG 2017-02-20 21:33] 13 - New York Republican Rep. Tom Reed Faces Angry Crowds, Deep In Trump Country\n",
      "[   DEBUG 2017-02-20 21:33] 14 - Republican Rep. Mark Sanford Discusses His South Carolina Town Hall\n",
      "[   DEBUG 2017-02-20 21:33] 15 - Rio's Carnival Is A Glitter-Filled Euphoria, Even If Brazil's Government Is Not\n",
      "[   DEBUG 2017-02-20 21:33] 16 - Imagining The Present As The Future Of The 1950s\n",
      "[   DEBUG 2017-02-20 21:33] 17 - A Foster Parent For Terminally Ill Children\n",
      "[   DEBUG 2017-02-20 21:33] 18 - Why NASA Is Exploring An Alien World In Antarctica\n",
      "[   DEBUG 2017-02-20 21:33] 19 - In 'Things We Lost,' Argentina's Haunted History Gets A Supernatural Twist\n",
      "[   DEBUG 2017-02-20 21:33] 20 - Alt.Latino Explores Afro-Latin Music For Black History Month\n",
      "[   DEBUG 2017-02-20 21:33] ***** parsing configuration for show: [Wait Wait Don't Tell Me]\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: Wait-Wait-Dont-Tell-Me\n",
      "[   DEBUG 2017-02-20 21:33] fetching episode info via HTML method\n",
      "[   DEBUG 2017-02-20 21:33] source: http://www.npr.org/programs/wait-wait-dont-tell-me/\n",
      "[   DEBUG 2017-02-20 21:33] HTML retrieved successfully\n",
      "[   DEBUG 2017-02-20 21:33] show date: 2017-02-18\n",
      "[   DEBUG 2017-02-20 21:33] JSON program information found for WAIT WAIT...DON'T TELL ME!\n",
      "[   DEBUG 2017-02-20 21:33] setting name to: Wait Wait Don't Tell Me\n",
      "[   DEBUG 2017-02-20 21:33] segments found: 9\n",
      "[   DEBUG 2017-02-20 21:33] adding trailing slash to path: 2017-02-18_WWTME\n",
      "[   DEBUG 2017-02-20 21:33] output path set to: ./output/Wait-Wait-Dont-Tell-Me/2017-02-18_WWTME/\n",
      "[   DEBUG 2017-02-20 21:33] m3u filename set to: 2017-02-18-WAIT-WAITDONT-TELL-ME.m3u\n",
      "[   DEBUG 2017-02-20 21:33] 1 - Who's Bill This Time\n",
      "[   DEBUG 2017-02-20 21:33] 2 - Panel Round One\n",
      "[   DEBUG 2017-02-20 21:33] 3 - Bluff The Listener\n",
      "[   DEBUG 2017-02-20 21:33] 4 - Not My Job: Author Nora Roberts (aka JD Robb) Gets Quizzed On J.D. Salinger\n",
      "[   DEBUG 2017-02-20 21:33] 5 - There Should Be A Word For That\n",
      "[   DEBUG 2017-02-20 21:33] 6 - Panel Round Two\n",
      "[   DEBUG 2017-02-20 21:33] 7 - Limericks\n",
      "[   DEBUG 2017-02-20 21:33] 8 - Lightning Fill In The Blank\n",
      "[   DEBUG 2017-02-20 21:33] 9 - Prediction\n",
      "[    INFO 2017-02-20 21:33] ---------- downloading episodes\n",
      "[   DEBUG 2017-02-20 21:33] found 5 episodes\n",
      "[    INFO 2017-02-20 21:33] ***** downloading: ALL THINGS CONSIDERED\n",
      "[    INFO 2017-02-20 21:33] downloading program: ALL THINGS CONSIDERED\n",
      "[   DEBUG 2017-02-20 21:33] checking for output directory: ./output/All-Things-Considered/2017-02-19_ATCO/\n",
      "[    INFO 2017-02-20 21:33] episode previously downloaded; skipping\n",
      "[    INFO 2017-02-20 21:33] ***** downloading: MORNING EDITION\n",
      "[    INFO 2017-02-20 21:33] downloading program: MORNING EDITION\n",
      "[   DEBUG 2017-02-20 21:33] checking for output directory: ./output/Morning-Edition/2017-02-20_MED/\n",
      "[   DEBUG 2017-02-20 21:33] output directory (./output/Morning-Edition/2017-02-20_MED/) not found\n",
      "[   DEBUG 2017-02-20 21:33] attempiting to create output directory\n",
      "[   DEBUG 2017-02-20 21:33] writing lockfile: ./output/Morning-Edition/2017-02-20_MED/.podcastdownload.lock\n",
      "[   DEBUG 2017-02-20 21:33] dryrun = False\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_fight_begins_to_wrest_control_of_western_mosul_from_isis.mp3?orgId=1&topicId=1010&d=320&p=3&story=516203117&t=progseg&e=516187826&seg=1&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/001_20170220_me_fight_begins_to_wrest_control_of_western_mosul_from_isis.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_the_mile_high_promise_and_risk_of_school_choice_.mp3?orgId=1&topicId=1013&aggIds=128851279&d=272&p=3&story=515359394&t=progseg&e=516187826&seg=2&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/002_20170220_me_the_mile_high_promise_and_risk_of_school_choice_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_got_back_pain_try_yoga_or_massage_before_reaching_for_the_pills.mp3?orgId=1&topicId=1128&aggIds=128851279&d=123&p=3&story=515675259&t=progseg&e=516187826&seg=3&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/003_20170220_me_got_back_pain_try_yoga_or_massage_before_reaching_for_the_pills.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_can_poetry_keep_you_young_science_is_still_out_but_the_heart_says_yes.mp3?orgId=1&topicId=1128&aggIds=128851279&d=265&p=3&story=514558968&t=progseg&e=516187826&seg=4&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/004_20170220_me_can_poetry_keep_you_young_science_is_still_out_but_the_heart_says_yes.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_hr1_return_-_rem_-_taylor.mp3?orgId=1&topicId=1124&d=28&p=3&story=516203142&t=progseg&e=516187826&seg=5&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/005_20170220_me_hr1_return_-_rem_-_taylor.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_famine_declared_in_south_sudan_after_3_years_of_civil_war.mp3?orgId=1&topicId=1126&d=266&p=3&story=516203177&t=progseg&e=516187826&seg=6&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/006_20170220_me_famine_declared_in_south_sudan_after_3_years_of_civil_war.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_have_spare_time_try_to_discover_a_planet.mp3?orgId=1&topicId=1026&aggIds=156490415&d=169&p=3&story=515810147&t=progseg&e=516187826&seg=7&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/007_20170220_me_have_spare_time_try_to_discover_a_planet.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_mattress_no_longer_delegated_to_bottom_of_shopping_list.mp3?orgId=1&topicId=1006&aggIds=128851279&d=232&p=3&story=515685098&t=progseg&e=516187826&seg=8&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/008_20170220_me_mattress_no_longer_delegated_to_bottom_of_shopping_list.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_alison_krauss_and_buddy_cannon_on_the_working_relationship_behind_windy_city.mp3?orgId=1&topicId=1105&aggIds=128851279&d=430&p=3&story=516138272&t=progseg&e=516187826&seg=9&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/009_20170220_me_alison_krauss_and_buddy_cannon_on_the_working_relationship_behind_windy_city.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_trump_pence_to_spend_presidents_day_working.mp3?orgId=1&topicId=1059&d=315&p=3&story=516203205&t=progseg&e=516187826&seg=10&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/010_20170220_me_trump_pence_to_spend_presidents_day_working.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_environmentalists_at_odds_with_kenyas_government_over_rail_line.mp3?orgId=1&topicId=1126&d=303&p=3&story=516203212&t=progseg&e=516187826&seg=11&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/011_20170220_me_environmentalists_at_odds_with_kenyas_government_over_rail_line.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_mexico_braces_for_flood_of_returnees_as_trump_cracks_down_on_immigration.mp3?orgId=1&topicId=1127&d=294&p=3&story=516203219&t=progseg&e=516187826&seg=12&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/012_20170220_me_mexico_braces_for_flood_of_returnees_as_trump_cracks_down_on_immigration.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_china_debates_response_to_the_killing_of_north_korean_kim_jong_nam.mp3?orgId=1&topicId=1125&d=126&p=3&story=516203226&t=progseg&e=516187826&seg=13&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/013_20170220_me_china_debates_response_to_the_killing_of_north_korean_kim_jong_nam.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_hr2_return.mp3?orgId=1&topicId=1004&d=27&p=3&story=516203236&t=progseg&e=516187826&seg=14&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/014_20170220_me_hr2_return.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_facebook_wants_great_power_but_what_about_responsibility_.mp3?orgId=1&topicId=1059&d=210&p=3&story=516094134&t=progseg&e=516187826&seg=15&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/015_20170220_me_facebook_wants_great_power_but_what_about_responsibility_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_scientists_measure_greenhouse_gases_as_they_fly_around_the_globe.mp3?orgId=168809220&topicId=1025&d=225&p=3&story=516203245&t=progseg&e=516187826&seg=16&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/016_20170220_me_scientists_measure_greenhouse_gases_as_they_fly_around_the_globe.mp3\n",
      "[   DEBUG 2017-02-20 21:33] downloading https://ondemand.npr.org/anon.npr-mp3/npr/me/2017/02/20170220_me_lead_ammunition_poisons_wildlife_but_too_expensive_to_change_hunters_say.mp3?orgId=583&topicId=1025&aggIds=128851279&d=222&p=3&story=514290612&t=progseg&e=516187826&seg=17&siteplayer=true\n",
      "[    INFO 2017-02-20 21:33] writing file to ./output/Morning-Edition/2017-02-20_MED/017_20170220_me_lead_ammunition_poisons_wildlife_but_too_expensive_to_change_hunters_say.mp3\n",
      "[    INFO 2017-02-20 21:33] opening m3u playlist: 2017-02-20-MORNING-EDITION.m3u\n",
      "[   DEBUG 2017-02-20 21:33] writing segments to: 2017-02-20-MORNING-EDITION.m3u\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 001_20170220_me_fight_begins_to_wrest_control_of_western_mosul_from_isis.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 002_20170220_me_the_mile_high_promise_and_risk_of_school_choice_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 003_20170220_me_got_back_pain_try_yoga_or_massage_before_reaching_for_the_pills.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 004_20170220_me_can_poetry_keep_you_young_science_is_still_out_but_the_heart_says_yes.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 005_20170220_me_hr1_return_-_rem_-_taylor.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 006_20170220_me_famine_declared_in_south_sudan_after_3_years_of_civil_war.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 007_20170220_me_have_spare_time_try_to_discover_a_planet.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 008_20170220_me_mattress_no_longer_delegated_to_bottom_of_shopping_list.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 009_20170220_me_alison_krauss_and_buddy_cannon_on_the_working_relationship_behind_windy_city.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 010_20170220_me_trump_pence_to_spend_presidents_day_working.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 011_20170220_me_environmentalists_at_odds_with_kenyas_government_over_rail_line.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 012_20170220_me_mexico_braces_for_flood_of_returnees_as_trump_cracks_down_on_immigration.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 013_20170220_me_china_debates_response_to_the_killing_of_north_korean_kim_jong_nam.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 014_20170220_me_hr2_return.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 015_20170220_me_facebook_wants_great_power_but_what_about_responsibility_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 016_20170220_me_scientists_measure_greenhouse_gases_as_they_fly_around_the_globe.mp3\n",
      "[   DEBUG 2017-02-20 21:33] writing segment to m3u file: 017_20170220_me_lead_ammunition_poisons_wildlife_but_too_expensive_to_change_hunters_say.mp3\n",
      "[    INFO 2017-02-20 21:33] tagging segments\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/001_20170220_me_fight_begins_to_wrest_control_of_western_mosul_from_isis.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/002_20170220_me_the_mile_high_promise_and_risk_of_school_choice_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/003_20170220_me_got_back_pain_try_yoga_or_massage_before_reaching_for_the_pills.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/004_20170220_me_can_poetry_keep_you_young_science_is_still_out_but_the_heart_says_yes.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/005_20170220_me_hr1_return_-_rem_-_taylor.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/006_20170220_me_famine_declared_in_south_sudan_after_3_years_of_civil_war.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/007_20170220_me_have_spare_time_try_to_discover_a_planet.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/008_20170220_me_mattress_no_longer_delegated_to_bottom_of_shopping_list.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/009_20170220_me_alison_krauss_and_buddy_cannon_on_the_working_relationship_behind_windy_city.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/010_20170220_me_trump_pence_to_spend_presidents_day_working.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/011_20170220_me_environmentalists_at_odds_with_kenyas_government_over_rail_line.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/012_20170220_me_mexico_braces_for_flood_of_returnees_as_trump_cracks_down_on_immigration.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/013_20170220_me_china_debates_response_to_the_killing_of_north_korean_kim_jong_nam.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/014_20170220_me_hr2_return.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/015_20170220_me_facebook_wants_great_power_but_what_about_responsibility_.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/016_20170220_me_scientists_measure_greenhouse_gases_as_they_fly_around_the_globe.mp3\n",
      "[   DEBUG 2017-02-20 21:33] tagging ./output/Morning-Edition/2017-02-20_MED/017_20170220_me_lead_ammunition_poisons_wildlife_but_too_expensive_to_change_hunters_say.mp3\n",
      "[    INFO 2017-02-20 21:33] success!\n",
      "[    INFO 2017-02-20 21:33] ***** cleaning up old episodes fpr MORNING EDITION\n",
      "[    INFO 2017-02-20 21:33] cleaning up stale shows for MORNING EDITION\n",
      "[    INFO 2017-02-20 21:33] keeping a maximum of 2 shows\n",
      "[   DEBUG 2017-02-20 21:33] searching path: ./output/Morning-Edition/\n",
      "[   DEBUG 2017-02-20 21:33] ./output/Morning-Edition/\n",
      "[   DEBUG 2017-02-20 21:33] ./output/Morning-Edition/2017-02-15_MED\n",
      "[   DEBUG 2017-02-20 21:33]       .podcastdownload.lock\n",
      "[   DEBUG 2017-02-20 21:33] ./output/Morning-Edition/2017-02-17_MED\n",
      "[   DEBUG 2017-02-20 21:33]       .podcastdownload.lock\n",
      "[   DEBUG 2017-02-20 21:33] ./output/Morning-Edition/2017-02-20_MED\n",
      "[   DEBUG 2017-02-20 21:33]       .podcastdownload.lock\n",
      "[   DEBUG 2017-02-20 21:33] previously downloaded episodes found: 3\n",
      "[   DEBUG 2017-02-20 21:33] flagged for deletion: ./output/Morning-Edition/2017-02-15_MED\n",
      "[   DEBUG 2017-02-20 21:33] attempting to clean episode files in: ./output/Morning-Edition/2017-02-15_MED\n",
      "[   DEBUG 2017-02-20 21:33] found lock file in path: ./output/Morning-Edition/2017-02-15_MED\n",
      "[   DEBUG 2017-02-20 21:33] deleting path: ./output/Morning-Edition/2017-02-15_MED\n",
      "\n",
      "[   DEBUG 2017-02-20 21:33] removed: [u'./output/Morning-Edition/2017-02-15_MED']\n",
      "[    INFO 2017-02-20 21:33] ***** downloading: WEEKEND EDITION SATURDAY\n",
      "[    INFO 2017-02-20 21:33] downloading program: WEEKEND EDITION SATURDAY\n",
      "[   DEBUG 2017-02-20 21:33] checking for output directory: ./output/Weekend-Edition-Saturday/2017-02-18_WESA/\n",
      "[    INFO 2017-02-20 21:33] episode previously downloaded; skipping\n",
      "[    INFO 2017-02-20 21:33] ***** downloading: WEEKEND EDITION SUNDAY\n",
      "[    INFO 2017-02-20 21:33] downloading program: WEEKEND EDITION SUNDAY\n",
      "[   DEBUG 2017-02-20 21:33] checking for output directory: ./output/Weekend-Edition-Sunday/2017-02-19_WESU/\n",
      "[    INFO 2017-02-20 21:33] episode previously downloaded; skipping\n",
      "[    INFO 2017-02-20 21:33] ***** downloading: WAIT WAIT...DON'T TELL ME!\n",
      "[    INFO 2017-02-20 21:33] downloading program: WAIT WAIT...DON'T TELL ME!\n",
      "[   DEBUG 2017-02-20 21:33] checking for output directory: ./output/Wait-Wait-Dont-Tell-Me/2017-02-18_WWTME/\n",
      "[    INFO 2017-02-20 21:33] episode previously downloaded; skipping\n"
     ]
    }
   ],
   "source": [
    "print sys.argv\n",
    "foo = mainNew(sys.argv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   DEBUG 2017-02-20 21:26] verifying configuration\n",
      "[   DEBUG 2017-02-20 21:26] show name set to: Morning Edition\n",
      "[   DEBUG 2017-02-20 21:26] fetchmethod set to: NPR_HTML\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar = foo[1]\n",
    "bar.verifyConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputpath': './output/', 'logfile': False, 'timeout': 5}\n"
     ]
    }
   ],
   "source": [
    "mainSection = 'Defaults'\n",
    "configParser = ConfigParser.SafeConfigParser()\n",
    "configParser.read('podcastdownload.ini')\n",
    "required = {'outputpath' : [configParser.get, './DownloadedShows']}\n",
    "\n",
    "default = {}\n",
    "for key in required:\n",
    "    try:\n",
    "        default[key] = required[key][0](mainSection, key)\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        \n",
    "print default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myLog = foo[1]\n",
    "print myLog.getEffectiveLevel()\n",
    "print logging.getLevelName(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.argv.append('-v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.argv.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARNING 2017-02-19 20:45] ignoring unknown command line options:\n",
      "[ WARNING 2017-02-19 20:45]      -f\n",
      "[ WARNING 2017-02-19 20:45]      /home/txoof/.local/share/jupyter/runtime/kernel-494d3a61-c4aa-4098-bc82-576399a4993d.json\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-09798659ef01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-60d0484df333>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meachEp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         if eachEp.download(parserArgs.dryrun, timeout = parserArgs.timeout, \n\u001b[0;32m--> 221\u001b[0;31m                            useragent = randomGenerator.choice(parserArgs.useragent.split('|'))):\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;31m# write m3u if there was a successful download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0meachEp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteM3U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-912c3832b053>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, dryrun, timeout, useragent)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     audioFile = urlopen(segment.audioURL, timeout = timeout, \n\u001b[0;32m--> 218\u001b[0;31m                           data = {'User-Agent' : useragent}).read()\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'could not download segment number: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 447\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m             return self.do_open(httplib.HTTPSConnection, req,\n\u001b[0;32m-> 1241\u001b[0;31m                 context=self._context)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# XXX what error?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;31m#message_body was not a string (i.e. it is a file) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m#we must run the risk of Nagle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_accept_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0mdatablock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "foo = main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'keya'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-dff2d6d2dadf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keya'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'keya'"
     ]
    }
   ],
   "source": [
    "bar = {'key': 'value'}\n",
    "print bar['keya']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
